---
title: "qml tutorial â€“ Week 8"
execute: 
  cache: true
---

```{r}
#| label: pkgs
#| message: false
#| echo: false

library(tidyverse)
theme_set(theme_light())
library(posterior)

library(brms)
library(broom.mixed)

options(ggplot2.discrete.fill = RColorBrewer::brewer.pal(8, "Dark2"))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(8, "Dark2"))

options(dplyr.summarise.inform = FALSE)

my_seed <- 8878
```

This tutorial has two sections, and each will guide you through one example of an interaction between two binary variables. The first section revisits the morphological processing data from the lecture. The second section focuses on a different data set, this time with a continuous outcome. This analysis will require you to adapt the code from earlier in the tutorial, as well as recall from earlier weeks how to fit and interpret a Gaussian model.

As usual, though, **first things first:**

1.  Create a new `.Rmd` file, save it in `code/`, and name it `tutorial-w08`.

2.  Include `knitr::opts_knit$set(root.dir = here::here())` in the `setup` chunk.

3.  Also in the `setup` chunk, include code to attach the libraries we'll use in this tutorial: `tidyverse`, `posterior`, `brms`, and `broom.mixed`.

## Lexical decision accuracy

### Read and process the data

We've played with the data in `shallow.csv` before, way back in week 2 (ah, the good old days!). This means you might already have it in your `data/` folder, but if not, you can download it again from here: [shallow.csv](../data/shallow.csv).

Use the usual `read_csv()` function to read in the dataset, and assign it to a variable called `shallow`.

```{r}
#| label: read-shallow-ex
#| eval: false

shallow <- ...
```

```{r}
#| label: read-shallow
#| echo: false
#| message: false

shallow <- read_csv("data/shallow.csv")
```

Run the following code to filter this data frame for only the data we need for this example.

```{r}
#| label: filter-shallow
shallow <- shallow %>% 
  filter(
    Group == "L1",
    Critical_Filler == "Critical",
    RT > 0,
    Relation_type != "NonConstituent"
  )
```

Next, we'll prepare our variables for analysis.

The **outcome variable** is `ACC`, accuracy (whether the response was correct or not). This variable is binary and it is now coded using `0` (for "incorrect") and `1` (for "correct"). This type of coding (using 0/1) is quite common. However, it makes it a bit more difficult to keep track of what 0 and 1 mean, especially when you have a bunch of binary variables.

As a general recommendation, it is best to code binary variables using meaningful labels. In the case of `ACC`, better, more transparent labels would be `incorrect` and `correct`. We will create a new column based on `ACC` with these new labels below.

The data also contains the two **predictor variables** we want:

-   `Relation_type`, with two levels: `Unrelated` and `Constituent`.
-   `Branching`, with two levels: `Left` and `Right`.

Can you see how the code below will ensure that each variable has the desired ordering for their levels? (Remember that by default the ordering is alphabetical!)

```{r}
#| label: var-setup-shallow

shallow <- shallow %>% 
  mutate(
    # Create Accuracy column based on ACC with desired order
    Accuracy      = ifelse(ACC == 1, "correct", "incorrect"), 
    # Order factor levels
    Accuracy      = factor(Accuracy, levels = c("incorrect", "correct")),
    Relation_type = factor(Relation_type, levels = c("Unrelated", "Constituent")),
    Branching     = factor(Branching, levels = c("Left", "Right"))
  )
```

### Visualise the data

Use `shallow` to create a bar plot that looks like this one. Show the proportion of correct/incorrect responses by `Relation_type`, faceting by `Branching`.

```{r}
#| label: barplot-shallow
#| echo: false
#| message: false

shallow %>% 
  ggplot(aes(x = Relation_type, fill = Accuracy)) +
  geom_bar(position = "fill") +
  facet_grid(~ Branching, labeller = labeller(Branching = label_both)) +
  labs(y = "Proportion",
       x = "Relation type")
```

::: {.callout-tip collapse="true" icon="false"}
#### Hint

A couple hints:

-   To make `geom_bar()` display proportions instead of counts, you can write `geom_bar(position = "fill")`.
-   To include the text "Branching" in the facet labels, give the function `facet_grid()` the following arguments:
    -   First, `~ Branching`, to tell it to facet by branching,
    -   and then `labeller = labeller(Branching = label_both)`.
:::

Notice that this plot reveals, among other things, a *difference of differences*: The difference between `Relation_type == Unrelated` and `Relation_Type == Constituent` is bigger when `Branching == Left`, and smaller when `Branching == Right`. **The only way to capture this difference of differences is to include an interaction between `Relation_type` and `Branching`.**


::: {.callout-important collapse="true" icon="false"}
#### Extra: More on contrasts

The `contrasts()` function takes as its argument a factor, and returns the coding that R will use to represent this factor in a model.

#### `Accuracy`

```{r}
contrasts(shallow$Accuracy)
```

Which level of `Accuracy`, our outcome variable, corresponds to a "success" in Bernoulli terms? How do we know? What does this mean for the estimates that the model will produce?

#### `Relation_Type`

```{r}
contrasts(shallow$Relation_type)
```

Because we are using 0/1 treatment coding, `Relation_type`'s $\beta$ coefficient tells us the effect of moving from the baseline level to the non-baseline level. In this case, the baseline is `Unrelated`, coded as 0. This means that the $\beta$ coefficient will represent the estimated effect of moving from `Unrelated` to `Constituent`.

In other words:

-   `Relation_type`'s $\beta$ coefficient's 95% CrI will be mostly or entirely **positive** if greater accuracy is associated with `Relation_type == Constituent` than with `Relation_type == Unrelated`.
-   Its $\beta$ coefficient's 95% CrI will be mostly or entirely **negative** if lower accuracy is associated with `Relation_type == Constituent` than with `Relation_type == Unrelated`.
-   Its $\beta$ coefficient's 95% CrI will be **centered around zero** if there is no clear association between accuracy and relation type.

Based on this information and on the bar plot above, do you expect that the coefficient's posterior distribution will be largely positive, negative, or around zero?

#### `Branching`

```{r}
contrasts(shallow$Branching)
```

Here, the baseline is `Left`, so the $\beta$ for `Branching` will represent the estimated effect of moving from `Left` to `Right`.

In other words:

-   `Branching`'s $\beta$ coefficient's 95% CrI will be mostly or entirely **positive** if greater accuracy is associated with `Branching == Right` than with `Branching == Left`.
-   Its $\beta$ coefficient's 95% CrI will be mostly or entirely **negative** if lower accuracy is associated with `Branching == Right` than with `Branching == Left`.
-   Its $\beta$ coefficient's 95% CrI will be **centered around zero** if there is no clear association between accuracy and branching.

Again, based on this, what kind of expectations do you have about this coefficient's posterior distribution?
:::

### Fit the model

From the lecture slides, here is the mathematical specification of the model we want to fit.

$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + (\beta_1 \times relation) + (\beta_2 \times branch) + (\beta_3 \times relation \times branch)\\
\beta_0 & \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 & \sim Gaussian(\mu_2, \sigma_2) \\
\beta_3 & \sim Gaussian(\mu_3, \sigma_3) \\
\end{aligned}
$$

Try to understand what each line mean before moving on.

We'll use `brm()` to fit a model called `acc_inter_bm`.

-   The model formula should specify that we're predicting `Accuracy` as a function of `Relation_type`, `Branching`, and their interaction.
-   Specify the correct family for the model as well as the data we'll draw on.
-   Include `backend = "cmdstanr"`.
-   Finish off by saving the model file using `brm()`'s `file` argument.

```{r}
#| label: shallow-fit-ex
#| eval: false
acc_inter_bm <- brm(
  ...
)
```

```{r}
#| label: shallow-fit
#| echo: false
#| message: false

acc_inter_bm <- brm(
  Accuracy ~ Relation_type + Branching + Relation_type:Branching,
  family = bernoulli(),
  data   = shallow,
  backend = "cmdstanr",
  file = "data/cache/acc_inter_bm"
)
```

Now run the model.

The summary should look something like this (but don't worry if your numbers are slightly different from these! That'll happen due to the randomness inherent in the MCMC sampling process).

```{r}
#| label: shallow-summ
summary(acc_inter_bm)
```


### Interpreting the interaction

For predictors using treatment contrasts, a positive interaction coefficient represents a positive adjustment to one variable's effect, when we go from the reference of other variable to its other level (or in other words, when we compare the second level to the reference level). And a negative interaction coefficient represents a negative adjustment.

As we observed in the lecture, the mean estimate of $-0.63$ we obtained in the model above suggests that:

-   There is on average a smaller effect of `Relation_type` in `Branching == Right` when compared to `Branching == Left` (the reference level); 
-   Or, equivalently, there is on average a smaller effect of `Branching` in `Relation_type == Constituent` when compared to `Relation_type == Unrelated` (the reference level).

However, the 95% CrI of the interaction is $[-1.72, 0.42]$ which includes both negative and positive values. In other words, while it seems that a negative adjustment is more probable (the range of negative values in the interval is greater than the positive range), a positive adjustment is also possible. This suggests that based on the model, the direction of the interaction is quite uncertain.

### Conditional posterior probability distributions

Getting the conditional posterior probability distributions when so many predictors are at play is a bit of a process, but we'll approach it step by step.

The first thing to do is to get the posterior draws from our model, using `as_draws_df()`.

```{r}
#| label: acc-draws
acc_draws <- as_draws_df(acc_inter_bm)
acc_draws
```

Each column that begins with `b_` contains draws from the posterior probability distribution of each of our model's $\beta$ parameters (see **Extra: Draws** to learn more). Can you identify which column corresponds to which model coefficient?

::: {.callout-important collapse="true" icon="false"}
#### Extra: Draws
The values in each column of the output of `as_draws_df()` are the values draws (Or, more accurately, each column contains a number of *draws* from the posterior distribution, as obtained by the MCMC sampling procedure.) that `summary()` summarises when it shows us the model's estimates.
:::

To know how to combine these columns to get the correct conditional posterior probability distributions, we have to reason about how the 0/1 treatment coding affects the presence or absence of the $\beta$s in the model equation, shown below:

$$
logit(p) = \beta_0 + (\beta_1 \times relation) + (\beta_2 \times branch) + (\beta_3 \times relation \times branch)
$$

Our goal is to figure out the conditional posterior probability distribution of $logit(p)$ (i.e., the log-odds of answering correctly) in each of our four combinations of levels. To do this, we substitute $relation$ and $branch$ in the equation with `0` or `1`, depending on the wanted levels (Remember that `0` is the reference level and `1` is the second level).

$$
\begin{aligned}
\text{Unrelated, Left:}     && \beta_0 &+ (\beta_1 \times 0) + (\beta_2 \times 0) + (\beta_3 \times 0) &&= \beta_0  &\\
\text{Unrelated, Right:}    && \beta_0 &+ (\beta_1 \times 0) + (\beta_2 \times 1) + (\beta_3 \times 0) &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   && \beta_0 &+ (\beta_1 \times 1) + (\beta_2 \times 0) + (\beta_3 \times 0) &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  && \beta_0 &+ (\beta_1 \times 1) + (\beta_2 \times 1) + (\beta_3 \times 1) &&= \beta_0 + \beta_1 + \beta_2 + \beta_3 &\\
\end{aligned}
$$

Make sure you understand why each 0 and 1 appears where it does.

Now we just need to reproduce this in R, using the code below. The output is a data frame where each column contains the conditional posterior draws of $logit(p)$ of each of the four combination of levels.

```{r}
#| label: acc-cond-pstr
#| warning: false

acc_draws_cond <- acc_draws %>% 
  mutate(
    Unrelated_Left = b_Intercept,
    Unrelated_Right = b_Intercept + b_BranchingRight,
    Constituent_Left = b_Intercept + b_Relation_typeConstituent,
    Constituent_Right = b_Intercept + b_BranchingRight + b_Relation_typeConstituent + `b_Relation_typeConstituent:BranchingRight`
  ) %>% 
  select(Unrelated_Left:Constituent_Right)

acc_draws_cond
```

::: {.callout-note icon="false"}
Note that, in `acc_draws`, the column name that corresponds to the interaction's $\beta$ contains `:`, which has a special meaning in R. (Try `nums <- 1:10` in the console). To avoid problems, we must wrap the column name using tick marks `` `b_Relation_typeConstituent:BranchingRight` ``.
:::

Now the conditional posterior draws are almost ready to work with! There's just one more data-manipulation step left before we can compute summary statistics and create pretty plots.

That step is to transform this data frame into "long" format using `pivot_longer()`. The goal is to change the data into a data frame with the following columns:

-   `predictors`, with the combinations of levels (`Unrelated_Left`, `Unrelated_Rigth`, ...);
-   `sampled_logodds`, with the posterior draws values.

```{r}
#| label: acc-pivot

acc_draws_cond_long <- acc_draws_cond %>% 
  pivot_longer(
    # The range of columns to pivot:
    Unrelated_Left:Constituent_Right,
    # Name the column that will contain the current headers:
    names_to = "predictors",
    # Name the column that will contain the current values:
    values_to = "sampled_logodds"
  )
acc_draws_cond_long
```

Can you see how `acc_draws_cond_long` contains the same data as `acc_draws_cond`, but in a different layout?

::: {.callout-tip}
#### Pivoting

**Pivoting** is the process of reshaping a data frame so that either the number of columns increases and that of rows decreases (`pivot_wider()`), or, vice versa, the number of columns decreases and that of rows increases (`pivot_longer()`).

These functions from the tidyverse package [tidyr](https://tidyr.tidyverse.org/index.html) are very powerful and it's very common to have to use them in data analyses.

To learn more about pivoting, check the [Pivoting](https://tidyr.tidyverse.org/articles/pivot.html) vignette.
:::

Now we have just a couple tiny things left:

-   We're going to use `separate()` to "separate" the `predictors` column into two columns: one with the value for `Relation_type`, and another for `Branching`. By default, column values are split at any punctuation character, like `_`. Have a look at [the documentation](https://tidyr.tidyverse.org/reference/separate.html) for `separate()` if you're curious about the details. The reverse of `separate()` is `unite()`.
-   `acc_draws_cond_long` is a new data frame, so R will apply its defaults for factor ordering unless we again order the factor levels manually.

```{r}
#| label: acc-draws-long-sep
acc_draws_cond_long <- acc_draws_cond_long %>% 
  # Separate `predictors` at "_" into two columns
  separate(predictors, into = c("Relation_type", "Branching")) %>% 
  # Set factor levels.
  mutate(
    Relation_type = factor(Relation_type, levels = c("Unrelated", "Constituent")),
    Branching     = factor(Branching, levels = c("Left", "Right"))
  )
acc_draws_cond_long
```

Nice!

We are finally ready to summarise and plot these distributions.

::: {.callout-note}
When computing the conditional posterior probability distributions when the model involves non-linear transformations like `log()` or `logit()`, it is very important to do any addition/subtraction of draws before transforming the values back to their original scale.

If you were to first back-transform each individual $\beta$ and then add them together, for example, this would give you incorrect estimates.

Try the following

```r
# Incorrect
plogis(0) + plogis(0)

# Correct
plogis(0 + 0)
```
:::

#### Compute means and 95% CrIs

Before moving on to plotting, we'll use `acc_draws_cond_long` to compute summary statistics of the posteriors. We can do this using some now-familiar functions: `group_by()`, `summarise()`, `mean()`, and `quantile2()`.

```{r}
#| label: acc-summ
acc_cond_summ <- acc_draws_cond_long %>% 
  group_by(Relation_type, Branching) %>% 
  summarise(
    # Calculate the lower and upper bounds of a 95% CrI + mean
    mean_logodds = mean(sampled_logodds),
    q95_lo = round(quantile2(sampled_logodds, probs = 0.025), 2),
    q95_hi = round(quantile2(sampled_logodds, probs = 0.975), 2),
    # Transform into probabilities
    p_mean   = round(plogis(mean_logodds), 2),
    p_q95_lo = round(plogis(q95_lo), 2),
    p_q95_hi = round(plogis(q95_hi), 2)
  )
acc_cond_summ
```

A good sense check to make sure that we did this computation correctly is to compare it to the output of `summary()`. Because `summary()` also computes summary measures using precisely those same posterior draws, we can compare the numbers in the model summary and in `acc_cond_summ`.

Specifically, in the model summary, the estimates for `Intercept` should match the summary measures here for `Relation_type == Unrelated` and `Branching == Left` (since those are the two baseline levels).

Let's have a look:

```{r}
#| label: acc-summ-fixef
#| echo: false

cat(capture.output(summary(acc_inter_bm))[8:13], sep = "\n")
```

Yes! The intercept's `Estimate` matches the mean when `Relation_type == Unrelated` and `Branching == Left`, and the lower and upper bounds of the 95% CrI match as well.

Now compute other CrI levels: 50%, 60, 75, and 85% (you have to work out which probabilities to use, given that for a 95% CrI we use 0.025 and 0.975).

#### Plot multiple posterior densities

Finally, we'll use the conditional posterior draws to create a density plot.

See if you understand how the following code creates the plot we see below.

```{r}
#| label: acc-dens-logodds
acc_draws_cond_long %>% 
  ggplot(aes(x = sampled_logodds, fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  labs(x = "Log-odds",
       y = "Probability density",
       title = "Conditional posterior probability of log-odds of 'correct' response",
       fill = "Relation type")
```

How would you create the same plot, but instead of the *x*-axis showing the data in log-odds, have the x axis showing the data back-transformed to probabilities? Something like this:

```{r}
#| label: acc-dens-prob
#| echo: false
#| message: false
acc_draws_cond_long %>% 
  ggplot(aes(x = plogis(sampled_logodds), fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  labs(x = "Probability",
       y = "Probability density",
       title = "Conditional posterior probability of probability of 'correct' response",
       fill = "Relation type")
```

Give it a shot. Creating this kind of plot is really worth practicing, because these are exactly the kinds of plots you'll want to show in your reports and dissertations.

OK, that's it for our first model! Now we'll turn to the second part of the tutorial: a more loosely-guided walkthrough of how to put a few different things you've learned so far into practice.

## Vowel duration in Italian and Polish

The data we'll use in this section comes from the paper *An exploratory study of voicing-related differences in vowel duration as compensatory temporal adjustment in Italian and Polish* (Coretta 2019, DOI: <https://doi.org/10.5334/gjgl.869>).

Read the abstract to see what the study is about.

The dataset can be downloaded here: [dur-ita-pol.csv](../data/dur-ita-pol.csv).

### Read in the data

Save `dur-ita-pol.csv` in your `data/` folder, and read it in using `read_csv()`.

```{r}
#| label: read-dur-ex
#| eval: false
dur_ita_pol <- ...
```

```{r}
#| label: read-dur
#| echo: false
#| message: false
dur_ita_pol <- read_csv("data/dur-ita-pol.csv")
```

The data you see should look something like this (selecting only a handful of the many columns to view!).

```{r}
#| label: dur-ita-pol
#| echo: false

dur_ita_pol %>% 
  select(speaker, word, vowel, v1_duration, c2_phonation, language)
```

The variables of interest for us are:

-   `v1_duration`: The duration of the first vowel in the word in milliseconds (ms).
-   `c2_phonation`: Whether the word's second consonant is voiced or voiceless.
-   `language`: The first language of the speaker (Italian or Polish).

The model we'll build below will predict `v1_duration` as a function of `c2_phonation`, `language`, and their interaction.

### Wrangle and plot the data

What kinds of transformations and level re-orderings, if any, will we need to do to prepare the data for analysis?

After you have prepared the data, make sure to create a few plots to see what the data looks like.




### Some thinking

Before fitting the model in the next section, try to answer the following questions based on what you have seen in the plots and based on the contrast coding of the predictors.

1.  Which level of each predictor corresponds to the **reference level**?

2.  Based on the plots above and on the contrast coding of `c2_phonation`, do you think the model's estimate for the coefficient of `c2_phonation` will be **positive, negative, or around zero?**

3.  What about the estimate for `language`?

4.  What about the interaction between `c2_phonation` and `language`?

### Fit the model

```{r}
#| label: dur-fit-ex
#| eval: false
dur_bm <- brm(
  ...
)
```

-   The model formula should specify that we're predicting log vowel duration as a function of `c2_phonation`, `language`, and their interaction (do you understand why we need to include the interaction?).
-   Use the appropriate model family.
-   Tell the model which dataset to draw from.
-   Use cmdstanr as the backend.
-   Save the model to a file.

```{r}
#| label: dur-fit
#| echo: false
dur_bm <- brm(
  log_v1_dur ~ c2_phonation * language,
  family = gaussian(),
  data   = dur_ita_pol,
  backend = "cmdstanr",
  file = "data/cache/dur_bm"
)
```

Here's what your model summary should look like (with possible small differences due to MCMC sampling).

```{r}
#| label: dur-fit-summ
summary(dur_bm)
```

How does this line up with your answers to the questions above?

### Interpreting the interaction

Here, the interaction coefficient 95% CrI is estimated to be [-0.05, 0.07].

This CrI is basically centered around zero, with near-equal probability assigned to both negative and positive values. This means that we can't be certain about the direction of the interaction's effect, or even whether there is an interaction at all.

Also, note how small the values in the 95% CrI are compared to the other coefficient, another sign that perhaps the interaction is very small and practically 0.

What does this mean for the cross-linguistic comparison of the effect of voicing on vowel duration?

### Conditional posterior probabilities

Now apply the workflow we went through above to this new model `dur_bm`. This will involve:

1.  Getting the posterior draws from the model using `as_draws_df()`.
2.  Work out which columns correspond to which $\beta$s.
3.  Add those columns together appropriately to cover all four combinations of the levels of `c2_phonation` and `language`.
4.  Transform the resulting data frame into "long" format using `pivot_longer()`.
5.  Separate the column headers into two columns, one of which corresponds to `c2_phonation` and the other, `language`.

Your data frame should have three columns: `c2_phonation`, `language`, and whatever you've chosen to name the column that contains the values of the posterior draws (perhaps something like `sampled_logms`).

Using this data, compute the mean and 95% CrIs of the conditional posterior probability distributions for every combination of `c2_phonation` and `language`, and create density plots.

These conditional posterior probability distributions are going to be in logs, because we log-transformed the durations to make them modellable as Gaussian. So, like the way we back-transformed the log-odds into probabilities above using `plogis()`, you'll also want to back-transform the log(ms) into ms by using the inverse of the `log()` function, which is `exp()`.

## Summary

::: {.callout-note appearance="minimal"}
**Modelling**

-   A model that contains interactions is able to estimate a difference in the effect of one predictor between levels of another.

-   For treatment-coded variables A and B, a positive interaction coefficient represents a positive adjustment (i.e., an addition) to variable A's effect, when we compare variable B's reference level to its otther level. And a negative interaction coefficient represents a negative adjustment (i.e., a subtraction).

- Null results (when a coefficient is practically 0) are still interpretable and valid results.

**Data processing and visualisation**

-   `separate()` can split up a single column into multiple ones, as long as every value in that column contains the same separator, e.g., `_`.

-   The same way that we back-transform log-odds into probabilities using `plogis()`, we can back-transform log values into the original space (here, ms) using `exp()`.

-   Any operations that we use to create conditional posterior probability distributions must be done on the scale in which the model was fit (e.g., log-odds or log), not the scale of the original variable (e.g., probability or ms). Back-transformation into the original space should be the final step.

-   To create density plots of multiple distributions, give ggplot the data in "long" format and let the `fill` aesthetic separate the data into differently-coloured densities. This also automatically creates a legend for each colour.
:::

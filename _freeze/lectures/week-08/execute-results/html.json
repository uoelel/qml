{
  "hash": "b1184c216a62163ed9f3e4530e65712e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"QML - Week 8\"\nsubtitle: \"Bernoulli regression models\"\nauthor: \"Stefano Coretta\"\nformat: revealjs\nbibliography: references.bib\n---\n\n\n\n## Bouba and kiki\n\n![](/img/Booba-Kiki.svg){fig-align=\"center\"}\n\n::: {style=\"font-size: 1rem;\"}\n@holland1964, @chen2016\n:::\n\n## Cross-modality\n\n::: {.callout-note appearance=\"simple\"}\n-   There are links between the auditory and visual modalities.\n\n-   A lot of research this concept, in fact originated with @kohler1929 who used \"takete\" and \"maluma\" (not the singer).\n\n-   @koppensteiner2016 ask if not only shape, but also motion patterns enter in the cross-modality link.\n:::\n\n## Motion patterns\n\n![](/img/pone.0150610.g001.PNG_L.png){fig-align=\"center\" width=\"500\"}\n\n::: {style=\"font-size: 1rem;\"}\n@koppensteiner2016\n:::\n\n## Motion patterns\n\n::: {.callout-note appearance=\"simple\"}\n@koppensteiner2016\n\n-   46 students (24 females and 22 males; age M = 25.1 years, SD = 3.6) of the University of Vienna.\n\n-   They saw a word (takete or maluma) and two stick-figures moving.\n\n-   They had to pick the stick figure they thought was described by the word.\n:::\n\n## The data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkopper <- read_delim(\"data/koppensteiner2016/takete_maluma.txt\")\nkopper\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 460 × 5\n   Tak_Mal_Stim Answer  Corr_1_Wrong_0 Rater                   Female_0\n   <chr>        <chr>            <dbl> <chr>                      <dbl>\n 1 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 2 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 3 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 4 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 5 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 6 Maluma       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 7 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 8 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n 9 Maluma       CORRECT              1 10MacI_12_10_11_59_.txt        0\n10 Takete       CORRECT              1 10MacI_12_10_11_59_.txt        0\n# ℹ 450 more rows\n```\n\n\n:::\n:::\n\n\n## Accuracy\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Accuracy by stimulus type.](week-08_files/figure-revealjs/fig-kopper-acc-1.png){#fig-kopper-acc width=672}\n:::\n:::\n\n\n## Modelling accuracy\n\n::: {.callout-note appearance=\"simple\"}\n-   We want to model the proportion of correct responses by stimulus type: both types should elicit the same level of accuracy.\n\n-   We can use a Bernoulli regression model.\n:::\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkopper <- kopper |> \n  mutate(\n    Answer_f = factor(Answer, levels = c(\"WRONG\", \"CORRECT\"))\n  )\nlevels(kopper$Answer_f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"WRONG\"   \"CORRECT\"\n```\n\n\n:::\n:::\n\n\n## Accuracy: Bernoulli regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkop_bm <- brm(\n  Answer_f ~ Tak_Mal_Stim,\n  data = kopper,\n  family = bernoulli,\n  cores = 4,\n  seed = 9128,\n  file = \"cache/kop_bm\"\n)\n```\n:::\n\n\n## Accuracy: model summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(kop_bm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: Answer_f ~ Tak_Mal_Stim \n   Data: kopper (Number of observations: 460) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept              0.81      0.15     0.52     1.11 1.00     3978     2479\nTak_Mal_StimTakete     0.15      0.21    -0.25     0.56 1.00     4026     2442\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## Expected predictions of accuracy\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week-08_files/figure-revealjs/kop-bm-cond-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Credible intervals of the difference\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|3-10|11\"}\nkop_bm_draws <- as_draws_df(kop_bm)\n\nkop_bm_draws |> \n  summarise(\n    `90%` = paste0(\"[\", paste(quantile2(b_Tak_Mal_StimTakete, c(0.05, 0.95)) |> round(2), collapse = \", \"), \"]\"),\n    `80%` = paste0(\"[\", paste(quantile2(b_Tak_Mal_StimTakete, c(0.1, 0.9)) |> round(2), collapse = \", \"), \"]\"),\n    `70%` = paste0(\"[\", paste(quantile2(b_Tak_Mal_StimTakete, c(0.15, 0.85)) |> round(2), collapse = \", \"), \"]\"),\n    `60%` = paste0(\"[\", paste(quantile2(b_Tak_Mal_StimTakete, c(0.2, 0.8)) |> round(2), collapse = \", \"), \"]\"),\n    `40%` = paste0(\"[\", paste(quantile2(b_Tak_Mal_StimTakete, c(0.3, 0.7)) |> round(2), collapse = \", \"), \"]\")\n  ) |> \n  knitr::kable(align = c(\"ccccc\"))\n```\n\n::: {.cell-output-display}\n\n\n|      90%      |      80%      |      70%      |      60%      |     40%      |\n|:-------------:|:-------------:|:-------------:|:-------------:|:------------:|\n| [-0.18, 0.49] | [-0.11, 0.42] | [-0.06, 0.37] | [-0.02, 0.33] | [0.04, 0.27] |\n\n\n:::\n:::\n\n\n## Is there a difference in accuracy by stimulus type?\n\n::: {.callout-note appearance=\"simple\"}\n-   According to the model, the difference in log-odds is \\[-0.25, 0.56\\] at 95% probability.\n\n-   Only at 40% probability we can argue for an increase in log-odds for takete stimuli between 0.04 and 0.27.\n\n-   We can't argue for or against a difference.\n    We just do not know.\n:::\n\n## References\n",
    "supporting": [
      "week-08_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "c4eefcb9285a748e55a2c62aa2fc3399",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"QML - Week 4\"\nsubtitle: \"Bayesian inference\"\nauthor: \"Stefano Coretta\"\nformat: revealjs\nbibliography: references.bib\n---\n\n## We're taking attendance\n\n![](/img/QRCode for Quantitative Methods in Linguistics and English Language, Semester 1, Week 4.png){fig-align=\"center\"}\n\n## Probabilities\n\n\n\n::: callout-note\n### Probability\n\n-   Probability of an event occurring.\n\n-   Probabilities can only be **between 0 and 1**.\n\n    -   ‚õîÔ∏è 0 means **impossible**.\n    -   ü§∑ 0.5 means **it can happen but it can also not happen**.\n    -   ‚úÖ 1 means **certain**.\n:::\n\n![](/img/probabilities.png){fig-align=\"center\"}\n\n## Probabilities\n\n::: {.callout-note appearance=\"simple\"}\n-   Probability of an event occurring: 0 to 100% probability.\n\n-   **Probability of a statistical variable being some numeric value**: a bit more complicated...\n:::\n\n. . .\n\n::: {.callout-tip appearance=\"simple\"}\n**We need probability distributions!**\n:::\n\n## Distribution of probability\n\n<br>\n\n![](/img/grubabilities.png){fig-align=\"center\"}\n\n## Probability distributions\n\n::: {.callout-note appearance=\"simple\"}\nA **probability distribution** describes *how the probabilities are distributed over the values* that a variable can take on.\n:::\n\n. . .\n\n::: callout-note\n### Two types of probability distributions\n\n-   Discrete probability distributions.\n\n-   Continuous probability distributions.\n:::\n\n. . .\n\n::: {.callout-tip appearance=\"simple\"}\nYou learned about discrete and continuous variables in Week 2!\n\n**Discrete variables (numeric or categorical) follow discrete probability distributions and continuous variables follow continuous probability distributions.**\n:::\n\n## Calculating probability distributions\n\n::: {.callout-note appearance=\"simple\"}\nYou will never need to calculate probability distributions by hand, but it is useful to know about the two mathematical functions that are used for that purpose.\n\n-   The **Probability Mass Function** (PMF) for discrete probability distributions.\n\n-   The **Probability Density Function** (PDF) for continuous probability distributions.\n:::\n\n## Probability Mass Function\n\n![](/img/dice.png){fig-align=\"center\"}\n\n## Probability Density Function\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week-04_files/figure-revealjs/pdf-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Parameters\n\n::: {.callout-note appearance=\"simple\"}\n-   **Probability distributions can be summarised with a set of parameters.**\n\n-   Different types of probability distributions have a different number of parameters and different parameters.\n:::\n\n. . .\n\n::: callout-tip\n### Gaussian distribution\n\nThe **Gaussian probability distribution** is a continuous probability distribution and it has two parameters:\n\n-   The mean $\\mu$.\n-   The standard deviation (SD) $\\sigma$.\n\nGo to [Seeing Theory](https://seeing-theory.brown.edu/probability-distributions/index.html#section2) (by Daniel Kunin).\n:::\n\n::: notes\nSeeing Theory was created by Daniel Kunin while an undergraduate at Brown University. The goal of this website is to make statistics more accessible through interactive visualizations (designed using Mike Bostock‚Äôs JavaScript library D3.js).\n\n<https://seeing-theory.brown.edu/index.html#3rdPage>\n:::\n\n## Simulate Gaussian data\n\n::: callout-note\n### Human height\n\n-   Simulate human height as a Gaussian variable.\n\n-   `rnorm()`: number of observations, mean, SD.\n:::\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(812)\nheight <- rnorm(200, 165, 8) |> round()\n\nheight[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 150 172 161 162 161 172 178 156 171 158\n```\n\n\n:::\n:::\n\n\n## Kernel Density Estimation\n\n::: {.callout-note appearance=\"simple\"}\n-   PDF constructs the density curve of theoretical distributions.\n\n-   **Kernel Density Estimation** (KDE) constructs the density curve of empirical data (observations).\n:::\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week-04_files/figure-revealjs/height-plot-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Statistical modelling\n\n::: {.callout-note appearance=\"simple\"}\n-   When you simulate data, you know the population mean and SD.\n\n-   In research, you don't. You just have observations.\n:::\n\n. . .\n\n::: callout-tip\n### Statistical modelling\n\n-   Statistical modelling allows you to estimate the mean and SD of the population from the sample. This is statistical inference.\n\n-   **Bayesian Gaussian models** do exactly that: estimate mean and SD.\n:::\n\n## Gaussian model of height\n\n$$\n\\begin{align}\nh & \\sim Gaussian(\\mu, \\sigma)\\\\\n\\mu & = ...\\\\\n\\sigma & = ...\n\\end{align}\n$$\n\n## Gaussian model of height\n\n$$\n\\begin{align}\nh & \\sim Gaussian(\\mu, \\sigma)\\\\\n\\mu & = P_\\mu\\\\\n\\sigma & = P_\\sigma\n\\end{align}\n$$\n\n::: {.callout-tip appearance=\"simple\"}\n-   $P$ is a **posterior probability distribution**.\n:::\n\n## Gaussian model of height: brms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh_tib <- tibble(h = height)\n\nlibrary(brms)\n\nh_bm <- brm(\n  h ~ 1,\n  family = gaussian,\n  data = h_tib,\n  file = \"cache/h_bm\"\n)\n```\n:::\n\n\n## Gaussian model of height: posteriors\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week-04_files/figure-revealjs/h-bm-plot-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## A bit harder: N = 5\n\n::: callout-note\n### Sample size\n\n-   Sample size matters: the lower the sample size, the higher the uncertainty.\n\n-   Let's try with just 5 observations (out of 200).\n:::\n\n## A bit harder: N = 5\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](week-04_files/figure-revealjs/h-bm-small-plot-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Summary\n\n::: {.callout-note appearance=\"simple\"}\n-   Probability distributions describe how probability is distributed across values.\n\n-   Theoretical probability distributions can be visualised with PMF/PDF and summarised with parameters.\n\n-   KDE is used for empirical distributions.\n\n-   (Bayesian) Gaussian models infer the population probability distribution from the data, by estimating posterior probability distributions of mean and SD.\n\n-   Sample size affects uncertainty.\n:::\n\n",
    "supporting": [
      "week-04_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
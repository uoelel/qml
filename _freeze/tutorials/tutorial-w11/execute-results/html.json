{
  "hash": "7962ec39b70dd60e7cf6fc57e67c217a",
  "result": {
    "markdown": "---\ntitle: \"QML tutorial – Week 11\"\nexecute: \n  freeze: auto\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Introduction\n\n::: callout-warning\n#### Important\n\nWhen working through these tutorials, always **make sure you are in the course RStudio Project** you created.\n\nYou know you are in an RStudio Project because you can see the name of the Project in the top-right corner of RStudio, next to the light-blue cube icon.\n\nIf you see `Project (none)` in the top-right corner, that means **you are not** in an RStudio Project.\n\nTo make sure you are in the RStudio project, you can open the project by going to the project folder in File Explorer (Win) or Finder (macOS) and double click on the `.Rproj` file.\n:::\n\nIn this optional tutorial, you'll run two linear models in the frequentist style. \nBoth of the models will use data that we've encountered in previous weeks. \nThis means that if you're curious, you can go back to the original Bayesian analyses to see how they compare to the frequentist ones we'll run today.\n\nBut, first things first: set up the Rmd file you'll use for this tutorial.\n\n1.  Create a new `.Rmd` file, save it in `code/`, and name it `tutorial-w11`.\n\n2.  In the `setup` chunk, include the line `knitr::opts_knit$set(root.dir = here::here())`.\n\n3.  Also in the `setup` chunk, include code to attach the libraries we'll use in this tutorial: `tidyverse` as usual, but now **two new packages:** `lme4` and `lmerTest`.\n\nIf you don't already have the packages `lme4` and `lmerTest` installed, then install them now.\n\n\n::: callout-tip\n#### Review: Choosing what kind of model to run\n\nIn previous weeks of this course, you've encountered different model families. Sometimes the model family is Gaussian (like in Weeks 4 and 5), and sometimes it is Bernoulli (like in Weeks 7 and 8).\nIn this tutorial, we'll be using the frequentist equivalents of these two model families. \n\nFor both Bayesian and frequentist statistics, **the choice of model is determined by what kind of variable the outcome (i.e., the dependent variable) is.**\n\nIf your outcome variable is **continuous** (potentially after transformation):\n\n- To fit a Bayesian model, use the Gaussian family.\n- To fit a frequentist model, use the function `lm()`, which stands for **\"linear model\"**.\n  - The model summary will automatically include p-values.\n\nIf your outcome variable is **binary** (e.g., 0/1, correct/incorrect, English/Scots):\n\n- To fit a Bayesian model, use the Bernoulli family.\n- To fit a frequentist model, use the function `glm()`, which stands for **\"generalised linear model\"**.\n  - The model summary will only include p-values if the `lmerTest` library is attached.\n\n:::\n\n\n## Modelling continuous outcomes with `lm()`\n\nFor the first part of this tutorial, we'll be using data we encountered [back in Week 5](https://uoelel.github.io/qml/tutorials/tutorial-w05.html).\nThis is the emotional valence data from [Winter (2016)](https://doi.org/10.1080/23273798.2016.1193619).\nWith this data, we'll look at whether there's a difference in emotional valence between smell words and taste words.\n\nIf you need to download the data again, right-click on the following link: [senses_valence.csv](../data/senses_valence.csv) (the file is also linked in [Course content](../content.qmd)) and save the file in `data/`.\n\nNow we are going to fit a model that will tell us **whether we can reject the null hypothesis that smell words and taste words have the same emotional valence.**\n\n\n### Prepare data for analysis\n\nPreparing the data is the same, whether we are fitting a Bayesian model or a frequentist one.\n\nLike we did in Week 5, we'll read in this data and filter it so that we're only looking at words with modalities of Smell or Taste.\nWe'll also use `mutate()` to convert this column into a factor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenses_valence <- read_csv(\"data/senses_valence.csv\") %>%\n  filter(Modality %in% c(\"Smell\", \"Taste\")) %>% \n  mutate(Modality = factor(Modality))\n```\n:::\n\n\nHere's a visualisation of the valence of each Smell and Taste word.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](tutorial-w11_files/figure-html/val-mod-violin-1.png){width=672}\n:::\n:::\n\n\nWe see that, on the whole, Taste words appear to have slightly higher emotional valence scores than Smell words, but there's also a fair amount of overlap.\n\n\n\n::: callout-tip\n#### Optional activity\n\nOnce you've finished working through the rest of the tutorial, why not come back to this point and practice your ggplot skills by recreating the plot above?\n\n:::\n\nBefore we fit the model, we should identify which level of our predictor `Modality` is the reference level.\n(This is true for both Bayesian and frequentist modelling.)\n\nBecause `Modality` is a factor, we can use the `contrasts()` function on it.\nThis function will tell us how each level of `Modality` is coded—in other words, what numeric representation it receives.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(senses_valence$Modality)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Taste\nSmell     0\nTaste     1\n```\n:::\n:::\n\n\nSo `Smell` is the reference level (the first level, the level coded as 0), and `Taste` is the non-reference level (the second level, the level coded as 1).\n\nThis information is all you need in order to tell what the numbers in the model summary are going to mean.\nWhat is the meaning of the Intercept going to be?\nWhat about the estimate of the slope coefficient, the effect of `Modality`?\n\n\n### Fit the model\n\n**Here is where things start to get different from what we're used to.**\n\nTo fit a Bayesian model, we used the function `brm()` from the library `brms`.\nNow, to fit a frequentist model to continuous outcome data, we use the function `lm()` from the library `lme4`.\n\nThe notation for the model formula is the same: `Valence ~ Modality`.\n\nThe only other information that `lm()` needs is the `data=` argument: the name of the data frame that contains the data we will analyse.\n\nCopy and run the following code that fits the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nval_lm <- lm(Val ~ Modality,\n             data = senses_valence)\n```\n:::\n\n\nNotice how fast it is to fit a frequentist model!\n\nIf you were reporting this model in a paper, you might write something like this.\n\n> We fitted a frequentist linear model with a Gaussian distribution.\nEmotional valence was the outcome variable and modality (smell vs. taste) was the only predictor. \nModality was coded with the default treatment contrasts, with \"smell\" as the reference level.\n\n\n::: {.callout-important collapse=\"true\"}\n#### Extra: Do I need to write \"frequentist\" in my report?\n\nIf you've read academic papers that include a statistical analysis, then chances are good that the authors simply write \"We fitted a linear model...\".\nIt is just assumed that the model is frequentist, because that is the traditional way of doing data analysis.\n\nGenerally, though, we'd encourage you to **be specific about the kind of analysis you've done.**\nAnd that includes mentioning what framework you're using for your statistical analysis—whether frequentist or Bayesian.\n:::\n\n\n### Interpret the model output\n\nLet's have a look at the model's estimates.\nLike in previous weeks, we can use the `summary()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(val_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Val ~ Modality, data = senses_valence)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.99315 -0.20870  0.04343  0.19115  0.62788 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.47101    0.06297  86.889  < 2e-16 ***\nModalityTaste  0.33711    0.07793   4.326 4.95e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3148 on 70 degrees of freedom\nMultiple R-squared:  0.2109,\tAdjusted R-squared:  0.1997 \nF-statistic: 18.71 on 1 and 70 DF,  p-value: 4.951e-05\n```\n:::\n:::\n\n\nLet's focus first on the table under `Coefficients:`, where there is one row per parameter. \nWhat does each column mean?\n\n- `Estimate`: This is the value that the model considers to be the **most likely** for that parameter.\n  - This is different from a Bayesian model summary. There, this estimate was the **posterior mean**, and the range of values that the model considered plausible was given by the 95% CrI.\n- `Std. Error`: The **standard error** is how much the `Estimate` would vary under hypothetical repeated sampling (i.e., if the exact same experiment were repeated a huge number of times, this is the standard deviation of all of those estimates). The standard error is computed based on the sample size and the standard deviation of the data we've observed, and we use it to compute the 95% confidence interval (CI).\n  - This is also different from a Bayesian model summary. There, the second column contained the **standard deviation of the posterior distribution.** No need to worry about hypothetical repeated sampling.\n- `t value`: Student's t, a measure of how different this estimate is from the null hypothesis. Generally, t-values between –2 and 2 are \"close enough\" to the null hypothesis, but **t-values that are more negative than –2 or more positive than 2 are \"unlikely enough\" that we are allowed to reject the null hypothesis.**\n- `Pr(>|t|)`: The probability of observing a t value more extreme than the one in the previous column. The number of `*` symbols tells us how unlikely the t-value is, under the null hypothesis (in other words, assuming that the parameter's true value is 0).\n\n\nNow let's interpret these results for each parameter.\nI'll include the `Coefficients:` table here again for convenience.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    5.47101    0.06297  86.889  < 2e-16 ***\nModalityTaste  0.33711    0.07793   4.326 4.95e-05 ***\n```\n:::\n:::\n\n\n**Intercept**:\n\n- When `Modality` = Smell (the reference level), the model estimates that `Valence` is 5.47 (SE = 0.06).\n- The 95% CI can be computed by adding and subtracting 1.96 $\\times$ SE from the estimate, so:\n  - Lower bound: 5.47 – (1.96 $\\times$ 0.06) = 5.35\n  - Upper bound: 5.47 + (1.96 $\\times$ 0.06) = 5.59\n- The null hypothesis (H0) that is tested here is that **the Intercept is equal to 0.**\n  - The t-value of 86.89 is *very* big.\n  - And the probability of observing a t-value this extreme or more extreme is miniscule (`2e-16` is the smallest number R can handle!).\n  - We therefore reject the null hypothesis that `Valence` for smell words is zero.\n  - **Is this an interesting hypothesis to test? Not really... it's going to be true for most datasets.**\n  \n**ModalityTaste**:\n\n- The model estimates that the difference between `Modality` = Smell and `Modality` = Taste is 0.34 (SE = 0.08, 95% CI: [0.18, 0.49]).\n- The null hypothesis (H0) that is tested here is that **this difference is 0.**\n  - The t-value of 4.33 is pretty big.\n  - And the probability of observing a t-value this extreme or more extreme is `4.95e-05`, that is, 0.0000495. Definitely below 0.05!\n  - We therefore reject the null hypothesis that the difference between smell and taste words is zero.\n  - **This is a more interesting hypothesis test, but it doesn't actually tell us if the difference between smell and taste words is different in the way we'd expect.** The effect might be totally backwards from what we hypothesised, but we'd still have to reject the null hypothesis.\n\nNotice that the meanings of the coefficients are still the same.\nThe intercept is still the estimated outcome for the reference level.\nAnd the predictor is still the estimated difference between the reference level and the non-reference level.\n\n\n### The full report\n\n> We fitted a frequentist linear model with a Gaussian distribution.\nEmotional valence was the outcome variable and modality (smell vs. taste) was the only predictor. \nModality was coded with the default treatment contrasts, with \"smell\" as the reference level.\n\n> According to the model, smell words have an emotional valence of 5.47 (SE = 0.06, 95% CI: [5.35, 5.59]). \nThe difference between smell words and taste words is 0.34 (SE = 0.08, 95% CI: [0.18, 0.49], p < 0.001).\n\nThe intercept being equal to zero is typically such a boring null hypothesis that there's no need to include the corresponding p-value in the report.\nBut it is typical to report the p-values for the other effects, where being equal to zero means that there is no difference between groups—and that's usually what we care about.\n\n\n## Modelling binary outcomes with `glm()`\n\nFor the second half of our exploration of frequentist modelling, we'll reuse data from [Week 9](https://uoelel.github.io/qml/tutorials/tutorial-w09.html) that originally comes from [Pankratz and van Tiel (2021)](https://www.doi.org/10.1017/langcog.2021.13).\nWith this data, we'll model the effects of log frequency, semantic distance, and their interaction on whether or not participants in an experiment drew a scalar inference. \n**Can we reject the null hypotheses that each of these predictors has no effect on the outcome?**\n\nIf you need to download the data again, right-click on the following link: [si.csv](../data/si.csv) (the file is also linked in [Course content](../content.qmd)) and save the file in `data/`.\n\n### Prepare the data for analysis\n\nWe'll transform the data the same way we did back in Week 9.\nThe following code shows a more streamlined way to do the same four steps that we did last time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsi <- read_csv(\"data/si.csv\") %>%\n  mutate(\n    SI = factor(SI, levels = c(\"no_scalar\", \"scalar\")),  # make SI into a factor\n    logfreq = log(freq),                                 # log the frequency\n    logfreq_c = logfreq - mean(logfreq),                 # centre logfreq\n    semdist_c = semdist - mean(semdist)                  # centre semdist\n  )\n```\n:::\n\n\nWithin one single instance of `mutate()`, we can create and modify several columns.\nNotice that we have created a brand new column `logfreq`, and in the very next line, we have centred it to create `logfreq_c`!\nSo if you ever have multiple operations that all use `mutate()`, you can bundle them all together like this.\n\nThe last step before running the model:  we want to know which level of `SI` is going to be coded as 1.\nWe can find this out with `contrasts()`, but for review, I want you to think it through for yourself first.\n\n**Before running any code or opening the following drop-down box,** decide whether you expect `no_scalar` or `scalar` to be coded as 1.\n\n\n::: {.callout-important collapse=\"true\"}\n#### Review: Coding of `SI` and why it matters\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(si$SI)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          scalar\nno_scalar      0\nscalar         1\n```\n:::\n:::\n\n\nWas your expectation correct?\n\n**Why does it matter how `SI` is coded?**\n\nThe model will estimate the log-odds of observing whichever level is coded as 1.\nSo, because `scalar` is coded as 1, the model will estimate the log-odds of getting a `scalar` response (that is, the log-odds of that experimental participant drawing a scalar inference).\nWe need to know which level is coded as 1 so that we know what the model's estimates mean.\n\n:::\n\nHere's a plot of this data from Week 9, showing that drawing a scalar inference is mostly associated with high values of both semantic distance and log frequency.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsi %>%\n  group_by(weak_adj) %>%\n  summarise(\n    prop_si = mean(as.numeric(SI) - 1),\n    logfreq_c = mean(logfreq_c),\n    semdist_c = mean(semdist_c)\n  ) %>%\n  ggplot(aes(logfreq_c, semdist_c, fill = prop_si)) +\n  geom_point(size = 3, pch = 21) +\n  scale_fill_distiller(type = \"div\") +\n  labs(\n    x = 'Logged frequency (centred)',\n    y = 'Semantic distance (centred)',\n    fill = 'Proportion\\nof scalar\\ninferences'\n  )\n```\n\n::: {.cell-output-display}\n![](tutorial-w11_files/figure-html/si-plot-1.png){width=672}\n:::\n:::\n\n\n\n\n### Fit the model\n\nTo analyse this binary outcome data, we can't just use any old linear model.\nWe're going to need a **generalised** linear model.\n\nA generalised linear model (often abbreviated as GLM) is what frequentists use whenever the outcome is not Gaussian.\nBinary data is just one situation where we would need a GLM.\nOther non-Gaussian outcomes might include count data, proportions between 0 and 1, and so on.\n\nTo fit a GLM, we will use the function `glm()`.\nIt needs the following information:\n\n- The usual kind of model formula that specifies what the outcome and predictors are.\n- In `data=`, we write the name of the data frame that contains our data.\n- In `family=`, we specify what *kind* of GLM to fit. But beware, here we write `binomial(link = \"logit\")` instead of `bernoulli()`.\n\nCopy and run the following code that fits the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsi_glm <- glm(SI ~ logfreq_c + semdist_c + logfreq_c:semdist_c,\n              data = si,\n              family = binomial(link = \"logit\"))\n```\n:::\n\n\n<!-- POSSIBLE TODO: \"Extra\" box on relationship between Bernoulli and binomial -->\n\nIf you were reporting this model in a paper, you might write something like this.\n\n> We fitted a frequentist binomial generalised linear model to estimate scalar inferencing as a function of logged word frequency, semantic distance, and their interaction. Both predictors were centred.\n\nAnother very common way to refer to this kind of model is to call it a \"logistic regression model\".\nIf you prefer that terminology, you could begin your report with:\n\n> We fitted a frequentist logistic regression model to estimate...\n\n(Don't you just *love* how every concept in statistics has ten different names?)\n\n\n### Interpret the model output\n\nTo see the model output, we can run the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(si_glm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = SI ~ logfreq_c + semdist_c + logfreq_c:semdist_c, \n    family = binomial(link = \"logit\"), data = si)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)         -0.69694    0.05131 -13.583  < 2e-16 ***\nlogfreq_c            0.52306    0.05083  10.290  < 2e-16 ***\nsemdist_c            0.08407    0.01248   6.734 1.66e-11 ***\nlogfreq_c:semdist_c  0.04987    0.01252   3.984 6.77e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2548.6  on 2005  degrees of freedom\nResidual deviance: 2398.2  on 2002  degrees of freedom\nAIC: 2406.2\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nNotice that here we have a column called `z value` instead of `t value`.\nFor present purposes, the difference is not important and does not affect how we interpret these results.\n\nLet's break down the interpretation of each coefficient.\n\n- **Intercept:** When centred log frequency and centred semantic distance are 0 (or in other words, when log frequency and semantic distance are at their means), the log-odds of making a scalar inference are –0.7 (SE = 0.05, 95% CI: [–0.8, –0.6]). \n  - Note that we again have a very small p-value, so we can reject the null hypothesis that the intercept is zero. But that's not really an interesting thing to do.\n  - Like before, we can use `plogis()` to back-transform this estimate into a probability: `plogis(-0.7)` is about 0.33.\n  \n- **logfreq_c:** When centred semantic distance is 0 (i.e., when semantic distance is at its mean), for a unit change in centred log frequency, the log-odds of making a scalar inference changes by 0.52 (SE = 0.05, 95% CI: [0.42, 0.62], p < 0.001).\n  - We reject the null hypothesis that there is no association between the log-odds of making a scalar inference and the log frequency of the words involved.\n  \n- **semdist_c:** When centred log frequency is 0 (i.e., when log frequency is at its mean), for a unit change in centred semantic distance, the log-odds of making a scalar inference changes by 0.08 (SE = 0.01, 95% CI: [0.06, 0.11], p < 0.001).\n  - We reject the null hypothesis that there is no association between the log-odds of making a scalar inference and the semantic distance between the words involved.\n  \n- **logfreq_c:semdist_c:**\n  - Two interpretations, as usual.\n    - A unit change in centred log frequency is associated with a positive adjustment to the effect of centred semantic distance of 0.05 (SE = 0.01, 95% CI: [0.03, 0.07], p < 0.001).\n    - A unit change in centred semantic distance is associated with a positive adjustment to the effect of centred log frequency of 0.05 (SE = 0.01, 95% CI: [0.03, 0.07], p < 0.001).\n  - The null hypothesis thus also has two interpretations.\n    - We reject the null hypothesis that centred log frequency has no influence on the effect of centred semantic distance.\n    - Equivalently, we reject the null hypothesis that centred semantic distance has no influence on the effect of centred log frequency.\n\n\n::: {.callout-important}\n#### `glm()` and p-values\n\nTo get p-values in from your GLM, make sure that you've attached the library `lmerTest` to your R markdown file.\n\nIf you only attached the library `lme4` and not the library `lmerTest` to your R markdown file, your GLM will not give you any p-values.\n\n:::\n\n### The full report\n\n> We fitted a frequentist binomial generalised linear model to estimate scalar inferencing as a function of logged word frequency, semantic distance, and their interaction. Both predictors were centred.\n\n> According to the model, when logged frequency and semantic distance are at their means, the probability of drawing a scalar inference is 33% ($\\beta$ = –0.69, SE = 0.05, 95% CI: [–0.8, –0.6]).\nFor each unit increase of logged frequency, when semantic distance is at its mean, the log-odds of drawing a scalar inference increases by 0.52 (SE = 0.05, 95% CI: [0.42, 0.62], p < 0.001).\nFor each unit increase of semantic distance, when logged frequency is at its mean, the log-odds of drawing a scalar inference increases by 0.08 (SE = 0.01, 95% CI: [0.06, 0.11], p < 0.001).\nThe positive effect of logged word frequency increases with increasing semantic distance by 0.05 (SE = 0.01, 95% CI: [0.03, 0.07], p < 0.001).\n\n\n::: {.callout-important collapse=\"true\"}\n#### Extra, FYI: Functions for fitting multilevel/hierarchical models\n\nIn your future work, it is likely that you'll need to run an analysis that involves so-called \"random effects\" (the frequentist term) or \"group-level effects\" (the term used in `brms`).\n\nRandom effects/group-level effects let you tell your model that **observations in your data set are not independent.**\nOne common situation is when your data contains multiple observations that come from the same person (e.g., if you've run an experiment or conducted a survey).\n\n**To fit a frequentist model that includes random effects, you'll need to know about two *more* functions:**\n\n- `lmer()`, which stands for \"Linear Mixed Effects Regression\", which you use if you have a continuous outcome.\n- `glmer()`, which stands for \"Generalised Linear Mixed Effects Regression\", which you use if you have a non-continuous outcome (e.g., a binary outcome).\n\n**To include group-level effects in a Bayesian model, you can still use Old Faithful, `brm()`.**\n\nStefano will hold a workshop in Semester 2 on how to include group-level effects in your models.\nDetails TBD!\n:::\n\n\n\n## Summary\n\n::: {.callout-note appearance=\"minimal\"}\n\n**What's the same between Bayesian and frequentist data analysis?**\n\n- We prepare data in the same way (including transforming and contrast-coding the variables we'll use).\n- In both cases, we choose the appropriate model based on what kind of data the outcome variable is.\n- The model formula uses the same syntax in `brm()`, `lm()`, and `glm()`: in all cases, we write `outcome ~ predictor1 + predictor2`.\n- The numbers in the model summary have the same meaning:\n  - The **intercept** is still the estimated outcome when all predictors are zero.\n  - The **effect of each predictor** is still the difference in the outcome for one unit change in that predictor (with all other predictors equal to zero).\n  - The **interaction term** is still an adjustment to the effect of one predictor for a unit increase in the value of the other predictor.\n  \n\n**What's different between Bayesian and frequentist data analysis?**\n\n- The conclusions that we are permitted to draw from a model are different.\n  - In Bayesian models, we focus mostly on the range of values contained in the 95% CrI. These are the values that the model considers plausible. **To what extent are these values consistent with our hypotheses?**\n  - In frequentist models, we focus mostly on the point value of the estimate, and on whether or not $p < 0.05$. **Can we reject the null hypothesis that there is no difference between levels of our predictor?**\n- Notice that the conclusions from a Bayesian model (**\"to what extent\"**) can give a lot more nuance than the conclusions from a frequentist model (**\"yes, reject\"** or **\"no, do not reject\"**).\n\n:::\n",
    "supporting": [
      "tutorial-w11_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
{
  "hash": "7a0d8d363bc9233148afd5a4e2e6d860",
  "result": {
    "markdown": "---\ntitle: \"QML tutorial – Week 11\"\nexecute: \n  freeze: auto\n---\n\n::: {.cell}\n\n:::\n\n\n## Introduction\n\n::: callout-warning\n#### Important\n\nWhen working through these tutorials, always **make sure you are in the course RStudio Project** you created.\n\nYou know you are in an RStudio Project because you can see the name of the Project in the top-right corner of RStudio, next to the light-blue cube icon.\n\nIf you see `Project (none)` in the top-right corner, that means **you are not** in an RStudio Project.\n\nTo make sure you are in the RStudio project, you can open the project by going to the project folder in File Explorer (Win) or Finder (macOS) and double click on the `.Rproj` file.\n:::\n\nIn this optional tutorial, you'll run two linear models in the frequentist style. \nBoth of the models will use data that we've encountered in previous weeks. \nThis means that if you're curious, you can go back to the original Bayesian analyses to see how they compare to the frequentist ones we'll run today.\n\nBut, first things first: set up the Rmd file you'll use for this tutorial.\n\n1.  Create a new `.Rmd` file, save it in `code/`, and name it `tutorial-w11`.\n\n2.  In the `setup` chunk, include the line `knitr::opts_knit$set(root.dir = here::here())`.\n\n3.  Also in the `setup` chunk, include code to attach the libraries we'll use in this tutorial: `tidyverse`, `lme4`, and `lmerTest` (**NOTE: Two of these are new!**).\n\nIf you don't already have the packages `lme4` and `lmerTest` installed, then install them now.\n\n::: callout-tip\n#### Review: Choosing what kind of model to run\n\nIn previous weeks of this course, you've encountered different model families. Sometimes the model family is Gaussian (like in Weeks 4 and 5), and sometimes it is Bernoulli (like in Weeks 7 and 8).\nIn this tutorial, we'll be using the frequentist equivalents of these two model families. \n\nFor both Bayesian and frequentist statistics, **the choice of model is determined by what kind of variable the outcome (i.e., the dependent variable) is.**\n\nIf your outcome variable is **continuous** (potentially after transformation):\n\n- To fit a Bayesian model, use the Gaussian family.\n- To fit a frequentist model, use the function `lm()`, which stands for **\"linear model\"**.\n\nIf your outcome variable is **binary** (e.g., 0/1, correct/incorrect, English/Scots):\n\n- To fit a Bayesian model, use the Bernoulli family.\n- To fit a frequentist model, use the function `glm()`, which stands for **\"generalised linear model\"**.\n\n:::\n\n\n## Modelling continuous outcomes with `lm()`\n\nFor the first part of this tutorial, we'll be using data we encountered [back in Week 5](https://uoelel.github.io/qml/tutorials/tutorial-w05.html).\nThis is the emotional valence data from [Winter (2016)](https://doi.org/10.1080/23273798.2016.1193619).\nWith this data, we'll look at whether there's a difference in emotional valence between smell words and taste words.\n\nIf you need to download the data again, right-click on the following link: [senses_valence.csv](../data/senses_valence.csv) (the file is also linked in [Course content](../content.qmd)) and save the file in `data/`.\n\nNow we are going to fit a model that will tell us **whether we can reject the null hypothesis that smell words and taste words have the same emotional valence.**\n\n\n### Prepare data for analysis\n\nPreparing the data is the same, whether we are fitting a Bayesian model or a frequentist one.\n\nLike we did in Week 5, we'll read in this data and filter it so that we're only looking at words with modalities of Smell or Taste.\nWe'll also use `mutate()` to convert this column into a factor.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenses_valence <- read_csv(\"data/senses_valence.csv\") %>%\n  filter(Modality %in% c(\"Smell\", \"Taste\")) %>% \n  mutate(Modality = factor(Modality))\n```\n:::\n\n\nHere's a visualisation of the valence of each Smell and Taste word.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](tutorial-w11_files/figure-html/val-mod-violin-1.png){width=672}\n:::\n:::\n\n\nWe see that, on the whole, Taste words appear to have slightly higher emotional valence scores than Smell words, but there's also a fair amount of overlap.\n\n\n\n::: callout-tip\n#### Optional activity\n\nOnce you've finished working through the rest of the tutorial, why not come back to this point and practice your ggplot skills by recreating the plot above?\n\n:::\n\nBefore we fit the model, we should identify which level of our predictor `Modality` is the reference level.\n(This is true for both Bayesian and frequentist modelling.)\n\nBecause `Modality` is a factor, we can use the `contrasts()` function on it.\nThis function will tell us how each level of `Modality` is coded—in other words, what numeric representation it receives.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(senses_valence$Modality)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Taste\nSmell     0\nTaste     1\n```\n:::\n:::\n\n\nSo `Smell` is the reference level (the first level, the level coded as 0), and `Taste` is the non-reference level (the second level, the level coded as 1).\n\nThis information is all you need in order to tell what the numbers in the model summary are going to mean.\nWhat is the meaning of the Intercept going to be?\nWhat about the estimate of the slope coefficient, the effect of `Modality`?\n\n\n### Fit the model\n\n**Here is where things start to get different from what we're used to.**\n\nTo fit a Bayesian model, we used the function `brm()` from the library `brms`.\nNow, to fit a frequentist model to continuous outcome data, we use the function `lm()` from the library `lme4`.\n\nThe notation for the model formula is the same: `Valence ~ Modality`.\n\nThe only other information that `lm()` needs is the `data=` argument: the name of the data frame that contains the data we will analyse.\n\nCopy and run the following code that fits the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nval_lm <- lm(Val ~ Modality,\n             data = senses_valence)\n```\n:::\n\n\nIf you were reporting this model in a paper, you might write something like this.\n\n> We fitted a frequentist linear model with emotional valence as the outcome variable and modality (smell vs. taste) as the only predictor. The modality predictor was coded with the default treatment contrasts (with \"smell\" as the reference level.)\n\n\n::: {.callout-important collapse=\"true\"}\n#### Extra: Do I need to write \"frequentist\" in my report?\n\nIf you've read academic papers that include a statistical analysis, chances are good that they are using frequentist statistics.\nSo most of the time, authors will simply write \"We fitted a linear model...\", and it is just assumed that the model is frequentist.\n\nGenerally, though, we'd encourage you to **be specific about the kind of analysis you've done.**\nAnd that includes mentioning what framework you're using for your statistical analysis—whether frequentist or Bayesian.\n:::\n\n\n### Interpret the model output\n\nLet's have a look at the model's estimates.\nLike in previous weeks, we can use the `summary()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(val_lm)\n```\n:::\n\n\nSome of this model summary may look familiar; some of it will look different.\n\n- TODO: How to report model results\n\n\n\n## Modelling binary outcomes with `glm()`\n\nFor the second half of our exploration of frequentist modelling, we'll reuse data from [Week 9](https://uoelel.github.io/qml/tutorials/tutorial-w09.html) that originally comes from [Pankratz and van Tiel (2021)](https://www.doi.org/10.1017/langcog.2021.13).\nWith this data, we'll model the effects of log frequency, semantic distance, and their interaction on whether or not participants in an experiment drew a scalar inference. \n**Can we reject the null hypotheses that each of these predictors has no effect on the outcome?**\n\nIf you need to download the data again, right-click on the following link: [si.csv](../data/si.csv) (the file is also linked in [Course content](../content.qmd)) and save the file in `data/`.\n\n### Prepare the data for analysis\n\nWe'll transform the data the same way we did back in Week 9.\nThe following code shows a more streamlined way to do the same four steps that we did last time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsi <- read_csv(\"data/si.csv\") %>%\n  mutate(\n    SI = factor(SI, levels = c(\"no_scalar\", \"scalar\")),  # make into a factor\n    logfreq = log(freq),                                 # log the frequency\n    logfreq_c = logfreq - mean(logfreq),                 # centre logfreq\n    semdist_c = semdist - mean(semdist)                  # centre semdist\n  )\n```\n:::\n\n\nWithin one single instance of `mutate()`, we can create and modify several columns.\nNotice that we have created a brand new column `logfreq`, and in the very next line, we have centred it to create `logfreq_c`!\nSo if you ever have multiple operations that all use `mutate()`, you can bundle them all together like this.\n\nThe last step before running the model:  we want to know which level of `SI` is going to be coded as 1.\nWe can find this out with `contrasts()`, but I want you to think it through for yourself first.\n\n**Before running any code or opening the following drop-down box,** decide whether you expect `no_scalar` or `scalar` to be coded as 1.\n\n\n::: {.callout-important collapse=\"true\"}\n#### Coding of `SI` and why it matters\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(si$SI)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          scalar\nno_scalar      0\nscalar         1\n```\n:::\n:::\n\n\nWas your expectation correct?\n\n**Why does it matter how `SI` is coded?**\n\nThe model will estimate the log-odds of observing whichever level is coded as 1.\nSo, because `scalar` is coded as 1, the model will estimate the log-odds of getting a `scalar` response (that is, the log-odds of that experimental participant drawing a scalar inference).\nWe need to know which level is coded as 1 so that we know what the model's estimates mean.\n\n:::\n\n\n### Fit the model\n\nTo analyse this binary outcome data, we can't just use any old linear model.\nWe're going to need a **generalised** linear model.\n\nA generalised linear model (often abbreviated as GLM) is what frequentists use whenever the outcome is not Gaussian.\nBinary data is just one situation where we would need a GLM.\nOther non-Gaussian outcomes might include count data, proportions between 0 and 1, and so on.\n\nTo fit a GLM, we will use the function `glm()`.\nIt needs the following information:\n\n- The usual kind of model formula that specifies what the outcome and predictors are.\n- In `data=`, we write the name of the data frame that contains our data.\n- In `family=`, we specify what *kind* of GLM to fit. But beware, here we write `binomial(link = \"logit\")` instead of `bernoulli()`.\n\nCopy and run the following code that fits the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsi_glm <- glm(SI ~ logfreq_c + semdist_c + logfreq_c:semdist_c,\n              data = si,\n              family = binomial(link = \"logit\"))\n```\n:::\n\n\n<!-- POSSIBLE TODO: \"Extra\" box on relationship between Bernoulli and binomial -->\n\nIf you were reporting this model in a paper, you might write something like this.\n\n> We fitted a frequentist binomial generalised linear model to estimate scalar inferencing as a function of logged word frequency, semantic distance, and their interaction. Both predictors were centred.\n\nAnother very common way to refer to this kind of model is to call it a \"logistic regression model\".\nIf you prefer that terminology, you could begin your report with:\n\n> We fitted a frequentist logistic regression model to estimate...\n\n(Don't you just *love* how every concept in statistics has ten different names?)\n\n\n### Interpret the model output\n\nTo see the model output, we can run the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(si_glm)\n```\n:::\n\n\n\n- How to report model results\n\n- We therefore reject the null hypothesis that X.\n- We therefore fail to reject the null hypothesis that X.\n\n::: {.callout-important}\n#### `glm()` and p-values\n\nTo get p-values in from your GLM, make sure that you've attached the library `lmerTest` to your R markdown file.\n\nIf you only attached the library `lme4` and not the library `lmerTest` to your R markdown file, your GLM would not give you any p-values.\n\n:::\n\n\n\n::: {.callout-important collapse=\"true\"}\n#### Extra, FYI: Functions for fitting multilevel/hierarchical models\n\nIn your future work, it is likely that you'll need to run an analysis that involves so-called \"random effects\" (the frequentist term) or \"group-level effects\" (the term used in `brms`).\n\nRandom effects/group-level effects let you tell your model that **observations in your data set are not independent.**\nOne common situation is when your data contains multiple observations that come from the same person (e.g., if you've run an experiment or conducted a survey).\n\n**To fit a frequentist model that includes random effects, you'll need to know about two *more* functions:**\n\n- `lmer()`, which stands for \"Linear Mixed Effects Regression\", which you use if you have a continuous outcome.\n- `glmer()`, which stands for \"Generalised Linear Mixed Effects Regression\", which you use if you have a non-continuous outcome (e.g., a binary outcome).\n\n**To include group-level effects in a Bayesian model, you can still use Old Faithful, `brm()`.**\n\nStefano will hold a workshop in Semester 2 on how to include group-level effects in your models.\nDetails TBD!\n:::\n\n\n\n## Summary\n\n::: {.callout-note appearance=\"minimal\"}\n\n**What's the same between Bayesian and frequentist data analysis?**\n\n- We prepare data in the same way (including transforming and contrast-coding the variables we'll use).\n- In both cases, we choose the appropriate model based on what kind of data the outcome variable is.\n- The model formula uses the same syntax in `brm()`, `lm()`, and `glm()`: in all cases, we write `outcome ~ predictor1 + predictor2`.\n- The numbers in the model summary have the same meaning:\n  - The **intercept** is still the estimated outcome when all predictors are zero.\n  - The **effect of each predictor** is still the difference in the outcome for one unit change in that predictor (with all other predictors equal to zero).\n  - The **interaction term** is still an adjustment to the effect of one predictor for a unit increase in the value of the other predictor.\n  \n\n**What's different between Bayesian and frequentist data analysis?**\n\n- The conclusions that we are permitted to draw from a model are different.\n  - In Bayesian models, we focus mostly on the range of values contained in the 95% CrI. These are the values that the model considers plausible. **To what extent are these values consistent with our hypotheses?**\n  - In frequentist models, we focus mostly on the point value of the estimate, and on whether or not $p < 0.05$. **Can we reject the null hypothesis that there is no difference between levels of our predictor?**\n- Notice that the conclusions from a Bayesian model (**\"to what extent\"**) can give a lot more nuance than the conclusions from a frequentist model (**\"yes, reject\"** or **\"no, do not reject\"**).\n\n:::\n",
    "supporting": [
      "tutorial-w11_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
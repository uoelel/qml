---
title: "Quantitative Methods for LEL"
subtitle: "Week 5"
author: "Dr Stefano Coretta"
institute: "University of Edinburgh"
date: "2023/10/17"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css:
      - ../xaringan-themer.css
      - ../custom.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "../macros.js"
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=7, fig.height=5, fig.retina=3,
  out.width = "60%", fig.align = "center",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
knitr::opts_knit$set(root.dir = here::here())

library(xaringanExtra)
use_xaringan_extra(c("panelset", "tachyons", "freezeframe"))

library(tidyverse)
theme_set(theme_light())
library(brms)
library(extraDistr)
library(ggdist)
library(glue)

options(ggplot2.discrete.fill = RColorBrewer::brewer.pal(8, "Dark2"))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(8, "Dark2"))
options(show.signif.stars = FALSE)
my_seed <- 8878
```

```{r read-data}
polite <- read_csv("data/polite.csv") %>%
  mutate(
    attitude = recode_factor(attitude, "inf" = "informal", "pol" = "polite")
  )

alb_vot <- read_csv("data/alb_vot.csv") %>%
  mutate(
    vot = (voi_onset - release) * 1000
  )

alb_vot_vl <- alb_vot %>%
  filter(
    label %in% c("k", "p", "t")
  ) %>%
  mutate(
    stop = label
  )
```

## Summary from last week

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- **Probability distributions**

  - Continuous vs discrete distributions.
  - Describe distributions: density functions and parameters.
  
- **Modelling continuous variables**

  - The Gaussian distribution has two parameters: mean $\mu$ and SD $\sigma$.

  - We can describe $\mu$ and $\sigma$ as probability distributions and estimate the (hyper-)parameters of those probability distributions.
  
- `brm()` from brms.
]

---

layout: true

## Comparing groups

---

```{r pol}
polite
```


---

```{r hnr}
polite %>%
  ggplot(aes(attitude, HNRmn, fill = attitude)) +
  geom_violin() +
  geom_jitter(width = 0.1, alpha = 0.5) +
  labs(
    y = "Harmonics-to-noise ratio (dB)",
    title = "Harmonics-to-noise ratio in Korean speakers"
  )
```


HNR is the ratio between periodicity and noise in the voice signal. Lower HNR values indicate less modal voice (i.e. creakier or breathier).

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- We want to estimate the probability distribution of harmonics-to-noise ratio (HNR) in Korean speakers.

  - Let's assume it is a Gaussian probability distribution.
  
  - So, `\(\text{HNR} \sim Gaussian(\mu, \sigma)\)`.
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- But we also want to estimate the difference in the mean (`\(\mu\)`) in the informal vs polite attitude conditions!
  
  - In other words, we need to allow the model to estimate $\mu$ based on attitude (informal vs polite).
]

---

.f3[
$$\text{HNR} \sim Gaussian(\mu, \sigma)$$
]

--
.f3[

$$
\begin{align}
\mu_{attitude=informal} & \sim Gaussian(\mu_1, \sigma_1) \\
\mu_{attitude=polite} & \sim Gaussian(\mu_2, \sigma_2) \\
\sigma & \sim TruncGaussian(\mu_3, \sigma_3)
\end{align}
$$
]

--

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
That would be great, but alas these models are set up in a different way by default!
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
These models are called *linear models*, or *regression models*, or *linear regression models*. They are a generalisation of the formula of a line:

$$
y = a + b \cdot x
$$
]

---

layout: false
layout: true

## Linear models

---

<iframe src="https://stefanocoretta.shinyapps.io/lines/" width="100%" height="500"></iframe>

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
.f3.center[
`brm(y ~ x)`
]

- The variable `y` to the left of `~` is called the **outcome variable** (aka response variable, dependent variable).

- The variable `x` to the right of `~` is called the **predictor variable** (aka independent variable).
]

--

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
There is a catch: linear models are meant to be used with numeric variables.

ðŸ˜± But... `attitude` is not a numeric predictor! 
]

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
Let's talk about coding of categorical variables!
]

---

layout: false
layout: true

## Coding categorical predictors

---

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
**NOTE**: What follows is for you how to understand how coding works, but remember that this is done automatically by R for you so you never have to do it by hand!!!
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Categorical predictors can be coded using numbers.**

There are two common types of coding systems:

- **Treatment** coding (this week's focus).

- **Sum** coding.
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
As with anything else in stats, **naming of coding systems is not an established matter** and the same coding can have different names, and vice versa the same name could refer to different systems.

For an excellent overview, see <https://debruine.github.io/faux/articles/contrasts.html>.
]

---

**Treatment** coding uses `0` and `1` to code categorical predictors.

.f3[
|               | attitude_pol |
| ------------- | -------:     |
| informal      | 0            |
| polite        | 1            |
]

--

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
With **treatment coding**, the first level in the predictor is the **reference level** (in `attitude`, it is `informal`).
]

--

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
**Level order**

By default, the ordering of levels in a categorical predictor is based on alphabetical order. But you can specify the order manually using the `factor()` function. (You will see how in the tutorial).
]

---

```{r att-coding}
polite %>%
  mutate(
    attitude_pol = ifelse(attitude == "informal", 0, 1)
  ) %>%
  select(HNRmn, attitude, attitude_pol)
```

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
**NOTE**: Remember that this is done automatically by R under the hood for you so you never have to do it by hand!!!

We will use `attitude` in the model.
]

---

layout: false
layout: true

## Comparing groups

---

.f4[
$$
\begin{align}
\text{HNR} & \sim Gaussian(\mu, \sigma) \\
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
[\text{formula of line: } y & = a + b \cdot x]
\end{align}
$$
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**For [attitude = informal]**, $attitude_{pol} = 0$:

$$
\begin{align}
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
    & = \beta_0 + \beta_1 \cdot 0 \\
    & = \beta_0
\end{align}
$$

**For [attitude = polite]**, $attitude_{pol} = 1$:

$$
\begin{align}
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
    & = \beta_0 + \beta_1 \cdot 1 \\
    & = \beta_0 + \beta_1
\end{align}
$$
]

---

.f4[
$$
\begin{align}
\text{HNR} & \sim Gaussian(\mu, \sigma) \\
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
[\text{formula of line: } y & = a + b \cdot x]
\end{align}
$$
]

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[

- $\beta_0$: (`Intercept`) mean HNR when [attitude = informal], the reference level of `attitude`.

- $\beta_1$: **difference** of mean HNR between [attitude = polite] and [attitude = informal].
  
$$
\begin{align}
\beta_1 & = \mu_{pol} - \mu_{inf} \\
        & = (\beta_0 + \beta_1) - (\beta_0) \\
        & = \beta_1
\end{align}
$$
]

---

.f4[
$$
\begin{align}
\text{HNR} & \sim Gaussian(\mu, \sigma) \\
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
[\text{formula of line: } y & = a + b \cdot x]
\end{align}
$$
]

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
`\(\beta_1\)` is the **effect of [attitude = polite]** on mean HNR relative to the baseline mean HNR when [attitude = informal].
]

--

.bg-washed-yellow.b--gold.ba.bw2.br3.shadow-5.ph4.mt2[
With **treatment coding**, the second level [polite] is compared against the reference level [informal].
]


---

.f4[
$$
\begin{align}
\text{HNR} & \sim Gaussian(\mu, \sigma) \\
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
\beta_0 & \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\sigma & \sim TruncGaussian(\mu_2, \sigma_2)
\end{align}
$$
]

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
We need to estimate:

- The **probability distribution of $\beta_0$**, i.e. the mean HNR when [attitude = informal].

- The **probability distribution of $\beta_1$**, i.e. the difference in mean HNR between [attitude = polite] and [attitude = informal]. 

- The **probability distribution of $\sigma$**, i.e. the standard deviation. 
]

---

.f4[
$$
\begin{align}
\text{HNR} & \sim Gaussian(\mu, \sigma) \\
\mu & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
\beta_0 & \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\sigma & \sim TruncGaussian(\mu_2, \sigma_2)
\end{align}
$$
]

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
In other words, we need to estimate the following hyperparameters: $\mu_0, \sigma_0, \mu_1, \sigma_1, \mu_2, \sigma_2$.
]

---

layout: false
layout: true

## Modelling HNR by attitude

---

```{r hnr-bm, echo=FALSE}
hnr_bm <- brm(
  HNRmn ~ attitude,
  data = polite,
  backend = "cmdstanr",
  cores = 4,
  file = "./data/cache/hnr_bm",
  seed = my_seed
)
```

```{r hnr-bm-code, eval=FALSE, echo=TRUE}
# Attach the brms package
library(brms)

# Run a Bayesian model
vot_bm <- brm(
  # This is the formula of the model.
  HNRmn ~ 1 + attitude,
  # This is the probability distribution family.
  family = gaussian(),
  # And the data.
  data = polite
)
```

---

.f2.center[
`HNRmn ~ 1 + attitude`
]

**Read as**: Model HNR values (`HNRmn`) as a function of (`~`) the mean (`1`) and attitude (`attitude`).

--

.f2.center[
`HNRmn ~ attitude`
]

We can omit the `1` (it is implied by default when there are other terms in the formula)! **You can read as**: Model HNR values (`HNRmn`) as a function of (`~`) attitude (`attitude`).

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- `HNRmn` is the **outcome variable** (aka response variable, dependent variable).

- `attitude` is the **predictor variable** (aka independent variables).
]

---

```{r hnr-bm-code-2, eval=FALSE, echo=TRUE}
vot_bm <- brm(
  # This is the formula of the model. We can omit `1`.
  HNRmn ~ attitude,
  # This is the probability distribution family.
  family = gaussian(),
  # And the data.
  data = polite
)
```

---

```{r hnr-bm-summ}
summary(hnr_bm)
```

---

```{r hnr-bm-summ-2}
hnr_bm_summ <- capture.output(summary(hnr_bm))
cat(hnr_bm_summ[8:11], sep = "\n")
```

--

<br>

.f4[
$$
\begin{align}
\mu     & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
\beta_0 & \sim Gaussian(16.27, 0.16) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1)
\end{align}
$$
]

- Parameter `\(\beta_0\)` (`Intercept`).

- **Estimate**: $\mu_0 = 16.27$ dB.

- **Est.Error**: $\sigma_0 = 0.16$ dB.


--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
When [attitude = informal], the probability distribution of $\mu$ is the probability distribution of $\beta_0$, which is $Gaussian(16.27, 0.16)$.
]

---

```{r hnr-int-p}
hnr_bm_draws <- as_draws_df(hnr_bm)
int_dens_l <- density(hnr_bm_draws$b_Intercept, adjust = 1.5)
int_dens <- tibble(
  x = int_dens_l$x,
  y = int_dens_l$y
)

hnr_int_p <- int_dens %>%
  ggplot(aes(x, y)) +
  geom_line(linewidth = 1) +
  scale_x_continuous(n.breaks = 6) +
  labs(
    title = expression(Probability~distribution~of~beta[0]),
    x = expression(beta[0]), y = "Probability density"
  ) +
  ylim(0, 3)
hnr_int_p
```

---

```{r hnr-int-p-2}
ci_low <- 15.97
ci_hi <- 16.59
label_y <- 2.75

hnr_int_p +
  geom_ribbon(
    aes(x = ifelse(x >= ci_low & x <= ci_hi, x, NA), ymin = 0, ymax = y),
    fill = "#9970ab",
    alpha = 0.4
  ) +
  annotate(
    "segment",
    x = ci_low, xend = ci_hi, y = label_y, yend = label_y,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    size = 1
  ) +
  annotate(
    "segment",
    x = ci_low, xend = ci_low, y = 0, yend = label_y,
    linetype = "dashed"
  ) +
  annotate(
    "segment",
    x = ci_hi, xend = ci_hi, y = 0, yend = label_y,
    linetype = "dashed"
  ) +
  annotate("label", x = ci_low + (ci_hi-ci_low)/2, y = label_y, label = "95% CrI")
```

--

There is a 95% probability that mean HNR when [attitude = informal] is between `r ci_low` and `r ci_hi` dB.


---

```{r nhr-bm-summ-3}
hnr_bm_summ <- capture.output(summary(hnr_bm))
cat(hnr_bm_summ[8:11], sep = "\n")
```

<br>

.f4[
$$
\begin{align}
\mu     & = \beta_0 + \beta_1 \cdot attitude_{pol} \\
\beta_0 & \sim Gaussian(16.27, 0.16) \\
\beta_1 & \sim Gaussian(1.25, 0.23)
\end{align}
$$
]

- Parameter: **`\(\beta_1\)`**.

- **Estimate**: $\mu_1 = 1.25$ dB.

- **Est.Error**: $\sigma_1 = 0.23$ dB.

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
The probability distribution of the difference between $\mu_{\text{attitude = polite}}$ and $\mu_{\text{attitude = informal}}$ is the probability distribution of $\beta_1$, which is $Gaussian(1.25, 0.23)$.
]

---

```{r hnr-att-p}
att_dens_l <- density(hnr_bm_draws$b_attitudepolite, adjust = 1.5)
att_dens <- tibble(
  x = att_dens_l$x,
  y = att_dens_l$y
)

hnr_att_p <- att_dens %>%
  ggplot(aes(x, y)) +
  geom_line(linewidth = 1) +
  scale_x_continuous(n.breaks = 6) +
  labs(
    title = expression(Probability~distribution~of~beta[1]),
    x = expression(beta[1]), y = "Probability density"
  ) +
  ylim(0, 2)
hnr_att_p
```

---

```{r hnr-att-p-2}
ci_low <- 0.8
ci_hi <- 1.7
label_y <- 2

hnr_att_p +
  geom_ribbon(
    aes(x = ifelse(x >= ci_low & x <= ci_hi, x, NA), ymin = 0, ymax = y),
    fill = "#9970ab",
    alpha = 0.4
  ) +
  annotate(
    "segment",
    x = ci_low, xend = ci_hi, y = label_y, yend = label_y,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    size = 1
  ) +
  annotate(
    "segment",
    x = ci_low, xend = ci_low, y = 0, yend = label_y,
    linetype = "dashed"
  ) +
  annotate(
    "segment",
    x = ci_hi, xend = ci_hi, y = 0, yend = label_y,
    linetype = "dashed"
  ) +
  annotate("label", x = ci_low + (ci_hi-ci_low)/2, y = label_y, label = "95% CrI")
```

--

There is 95% probability that the difference in mean HNR between $\mu_{\text{attitude = polite}}$ and $\mu_{\text{attitude = informal}}$ is between `r ci_low` and `r ci_hi` dB.

---

```{r hnr-sig-p}
sig_dens_l <- density(hnr_bm_draws$sigma, adjust = 1.5)
sig_dens <- tibble(
  x = sig_dens_l$x,
  y = sig_dens_l$y
)

hnr_sig_p <- sig_dens %>%
  ggplot(aes(x, y)) +
  geom_line(linewidth = 1) +
  scale_x_continuous(n.breaks = 6) +
  labs(
    title = expression(Probability~distribution~of~sigma),
    x = expression(sigma), y = "Probability density"
  ) +
  ylim(0, 5)
hnr_sig_p
```

---

```{r hnr-sig-p-2}
ci_low <- 1.54
ci_hi <- 1.86
label_y <- 5

hnr_sig_p +
  geom_ribbon(
    aes(x = ifelse(x >= ci_low & x <= ci_hi, x, NA), ymin = 0, ymax = y),
    fill = "#9970ab",
    alpha = 0.4
  ) +
  annotate(
    "segment",
    x = ci_low, xend = ci_hi, y = label_y, yend = label_y,
    arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm")),
    size = 1
  ) +
  annotate(
    "segment",
    x = ci_low, xend = ci_low, y = 0, yend = label_y,
    linetype = "dashed"
  ) +
  annotate(
    "segment",
    x = ci_hi, xend = ci_hi, y = 0, yend = label_y,
    linetype = "dashed"
  ) +
  annotate("label", x = ci_low + (ci_hi-ci_low)/2, y = label_y, label = "95% CrI")
```

--

There is a 95% probability that the standard deviation of the probability distribution of HNR values is between `r ci_low` and `r ci_hi` dB.

---

layout: false
class: center middle reverse

## MID-TERM COURSE EVALUATION

---

layout: true

## Modelling VOT by stop

---

```{r vot-1}
alb_vot_vl %>%
  ggplot(aes(vot)) +
  geom_density(fill = "gray", alpha = 0.5) +
  geom_rug() +
  labs(
    title = "VOT of Albanian stops",
    x = "VOT (ms)", y = "Probability density"
  )
```

---

```{r vot-2}
alb_vot_vl %>%
  ggplot(aes(vot, fill = stop)) +
  geom_density(alpha = 0.5) +
  geom_rug() +
  labs(
    title = "VOT of Albanian stops",
    x = "VOT (ms)", y = "Probability density"
  )
```

---

```{r vot-3}
alb_vot_vl %>%
  ggplot(aes(stop, vot, colour = stop)) +
  geom_jitter(width = 0.1, size = 3, alpha = 0.5) +
  labs(
    title = "VOT of Albanian stops",
    x = "Stop", y = "VOT (ms)"
  )
```

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- We want to estimate the probability distribution of Voice Onset Time (VOT) in Albanian voiceless stops /k, p, t/.

  - Let's assume it is a Gaussian probability distribution.
  
  - So, `\(\text{VOT} \sim Gaussian(\mu, \sigma)\)`.
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- But we also want to estimate the difference in the mean (`\(\mu\)`) in each stop /k, p, t/!
  
  - In other words, we need to allow the model to estimate $\mu$ based on the stop.
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
ðŸ˜± But... `stop` is not a numeric predictor! 
]

---

**Treatment** coding uses `0` and `1` to code categorical predictors. **But** now we have three levels (`k, p, t`) so `0` and `1` are not enough.

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
In treatment coding, **N-1 dummy variables** are created where N is the number of levels.

- `attitude` has two levels (informal vs polite) so we need $N-1 = 2-1 = 1$ dummy variable: `attitude_pol`.

- `stop` has three levels (/k, p, t/) so we need $N-1 = 3-1 = 2$ dummy variables: `stop_p` and `stop_t`.
]

--

<br>

|   | stop_p | stop_t |
|---|--------|--------|
| k | 0      | 0      |
| p | 1      | 0      |
| t | 0      | 1      |


---

.f3[
$$\text{VOT} \sim Gaussian(\mu, \sigma)$$
]

--

.f3[
$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- $\beta_0$: mean VOT when [stop = /k/].

  - `k` is the reference level because of the alphabetical order in `k, p, t`.

- $\beta_1$: difference of mean VOT between [stop = /p/] and [stop = /k/].

  - $\beta_1 = \mu_{p} - \mu_{k}$
  
  - **`\(\beta_1\)` is the effect of [stop = /p/] on mean VOT relative to the baseline mean VOT when [stop = k]**.

- $stop_p$: is 0 for [stop = /k/] and [stop = /t/] and 1 for [stop = /p/].
]

---

.f3[
$$\text{VOT} \sim Gaussian(\mu, \sigma)$$
]

.f3[
$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- $\beta_2$: difference of mean VOT between [stop = /t/] and [stop = /k/].

  - $\beta_2 = \mu_{t} - \mu_{k}$
  
  - **`\(\beta_2\)` is the effect of [stop = /t/] on mean VOT relative to the baseline mean VOT when [stop = k]**.

- $stop_t$: is 0 for [stop = /k/] and [stop = /p/] and 1 for [stop = /t/].
]

---


.f3[
$$\text{VOT} \sim Gaussian(\mu, \sigma)$$
]

.f3[
$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
$$\mu_{\text{(stop = k)}} = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t = \beta_0 + \beta_1 \cdot 0 + \beta_2 \cdot 0 = \beta_0$$

$$\mu_{\text{(stop = p)}} = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t = \beta_0 + \beta_1 \cdot 1 + \beta_2 \cdot 0 = \beta_0 + \beta_1$$

$$\mu_{\text{(stop = t)}} = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t = \beta_0 + \beta_1 \cdot 0 + \beta_2 \cdot 1 = \beta_0 + \beta_2$$
]

---

$$\text{VOT} \sim Gaussian(\mu, \sigma)$$

$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$

$$\beta_0 \sim Gaussian(\mu_0, \sigma_0)$$

$$\beta_1 \sim Gaussian(\mu_1, \sigma_1)$$

$$\beta_2 \sim Gaussian(\mu_2, \sigma_2)$$

$$\sigma \sim TruncGaussian(\mu_3, \sigma_3)$$

--

<br>

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
We need to estimate $\mu_0$, $\sigma_0$, $\mu_1$, $\sigma_1$, $\mu_2$, $\sigma_2$, $\mu_3$, $\sigma_3$.
]

---

```{r vot-bm-2, echo=FALSE}
vot_bm_2 <- brm(
  vot ~ stop,
  data = alb_vot_vl,
  backend = "cmdstanr",
  cores = 4,
  file = "./data/cache/vot_bm_2",
  seed = my_seed
)
```

```{r vot-bm-2-code, eval=FALSE, echo=TRUE}
# Run a Bayesian model
vot_bm <- brm(
  # This is the formula of the model.
  vot ~ stop,
  # This is the probability distribution family.
  family = gaussian(),
  # And the data.
  data = alb_vot_vl
)
```

---

```{r vot-bm-2-summ}
summary(vot_bm_2)
```

---

```{r vot-bm-2-summ-2}
vot_bm_summ <- capture.output(summary(vot_bm_2))
cat(vot_bm_summ[8:12], sep = "\n")
```

--

<br>
<br>

.pull-left[
- **Intercept**: $\mu_{\text{stop = k}} = \beta_0$.

- **Estimate**: $\mu_0 = 54.12$ ms.

- **Est.Error**: $\sigma_0 = 4.44$ ms.
]

.pull-right[
$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$

.purple[
$$\beta_0 \sim Gaussian(54.12, 4.14)$$
]

$$\beta_1 \sim Gaussian(\mu_1, \sigma_1)$$

$$\beta_2 \sim Gaussian(\mu_2, \sigma_2)$$
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
When [stop = k], the probability distribution of $\mu$ is the probability distribution of $\beta_0$, which is $Gaussian(54.12, 4.12)$.
]

---


```{r vot-bm-2-summ-3}
vot_bm_summ <- capture.output(summary(vot_bm_2))
cat(vot_bm_summ[8:12], sep = "\n")
```

<br>
<br>

.pull-left[
- **stopp**: $\beta_1$.

- **Estimate**: $\mu_1 = -40.55$ ms.

- **Est.Error**: $\sigma_1 = 6.27$ ms.
]

.pull-right[
$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$

$$\beta_0 \sim Gaussian(54.12, 4.14)$$

.purple[
$$\beta_1 \sim Gaussian(-40.55, 6.27)$$
]

$$\beta_2 \sim Gaussian(\mu_2, \sigma_2)$$
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
When [stop = p], the probability distribution of the difference between $\mu_{\text{stop = p}}$ and $\mu_{\text{stop = k}}$ is the probability distribution of $\beta_1$, which is $Gaussian(-40.55, 6.27)$.
]

---

```{r vot-bm-2-summ-4}
vot_bm_summ <- capture.output(summary(vot_bm_2))
cat(vot_bm_summ[8:12], sep = "\n")
```

<br>
<br>

.pull-left[
- **stopp**: $\beta_2$.

- **Estimate**: $\mu_2 = -39.42$ ms.

- **Est.Error**: $\sigma_2 = 6.32$ ms.
]

.pull-right[
$$\mu = \beta_0 + \beta_1 \cdot stop_p + \beta_2 \cdot stop_t$$

$$\beta_0 \sim Gaussian(54.12, 4.14)$$

$$\beta_1 \sim Gaussian(-40.55, 6.27)$$

.purple[
$$\beta_2 \sim Gaussian(-39.42, 6.32)$$
]
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
When [stop = t], the probability distribution of the difference between $\mu_{\text{stop = t}}$ and $\mu_{\text{stop = k}}$ is the probability distribution of $\beta_2$, which is $Gaussian(-39.42, 6.32)$.
]

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**IMPORTANT**

- While $\beta_0$ is the probability distribution of mean VOT when [stop = k]

- $\beta_1$ and $\beta_2$ are the probability distributions of the **DIFFERENCE** between mean VOT when [stop = p] and when [stop = k], and when [stop = t] and when [stop = k], respectively.

- $\beta_1$ and $\beta_2$ are **NOT** the probability distributions of the mean VOT when [stop = p] and when [stop = t]!
]

---

layout: false

## Summary

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- **Comparing groups** with `brm()`

  - `outcome ~ predictor`.
  - Categorical predictor with 2 and 3 levels.

- **Treatment coding** of categorical predictors.

  - N-1 **dummy variables**, where N is number of levels in the predictor.
  - Level ordering is *alphabetical* but you can specify your own.
  - **NOTE**: you don't have to apply treatment coding yourself! It's done under the hood by R.

- **Remember**

  - The **Intercept** $\beta_0$ is the mean of the reference level.
  - The other $\beta$'s are the **difference** of the other levels relative to the reference level.
]

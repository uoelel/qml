---
title: "Quantitative Methods for LEL"
subtitle: "Week 8 - Multiple predictors and interactions"
author: "Stefano Coretta and Elizabeth Pankratz"
institute: "University of Edinburgh"
date: "2023/11/07"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css:
      - ../xaringan-themer.css
      - ../custom.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "../macros.js"
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.width=7, fig.height=5, fig.retina=3,
  out.width = "60%", fig.align = "center",
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE,
  hiline = TRUE
)
knitr::opts_knit$set(root.dir = here::here())

library(xaringanExtra)
use_xaringan_extra(c("panelset", "tachyons", "freezeframe"))

library(tidyverse)
theme_set(theme_light())
library(brms)
library(extraDistr)
library(ggdist)
library(glue)
library(posterior)

options(ggplot2.discrete.fill = RColorBrewer::brewer.pal(8, "Dark2"))
options(ggplot2.discrete.colour = RColorBrewer::brewer.pal(8, "Dark2"))
options(show.signif.stars = FALSE)
my_seed <- 8878
```

```{r read-data}
shallow <- read_csv("data/shallow.csv") %>%
  filter(
    Group == "L1",
    Critical_Filler == "Critical",
    RT > 0
  ) %>%
  mutate(
    Accuracy = ifelse(ACC == 1, "correct", "incorrect"),
    Accuracy = factor(Accuracy, levels = c("incorrect", "correct"))
  )
```

## Summary from last week

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- **Binary outcomes** are outcome variables with two discrete levels (e.g., yes/no, grammatical/ungrammatical, correct/incorrect).

- We can visualise binary outcomes as **proportions**.

- Binary outcomes follow the Bernoulli distribution which has one parameter, $p$, the probability of "success" (`family = bernoulli()`).

- A Bernoulli model returns estimates in log-odds. We can convert log-odds into probabilities with the logistic function (`plogis()`).

- A Bayesian Credible Interval (CrI) tells you the region in which, with some probability (like 95%, 60%, 73%, etc), the true value lies.
]

---

<iframe allowfullscreen frameborder="0" height="100%" mozallowfullscreen style="min-width: 500px; min-height: 355px" src="https://app.wooclap.com/events/SQQFXB/questions/65436cf3c1a55c4249b6d94e" width="100%"></iframe>

---

layout: true

## The `shallow` data: Relation type and Branching

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Lexical decision task:** Is the string you see a word in English or not?

- Outcome variable: **Accuracy** (incorrect vs correct).

- Predictors: 

  - **Relation_type**: unrelated, non-constituent, constituent.
  
  - **Branching**: left ([[un-[ripe]]-ness]), right ([un-[[grace]-ful]]).
]

---

```{r shallow}
shallow %>% select(Group, ID, Accuracy, Relation_type, Branching)
```

---

```{r shallow-plot}
shallow %>%
  ggplot(aes(Relation_type, fill = Accuracy)) +
  geom_bar(position = "fill") +
  facet_grid(cols = vars(Branching)) +
  labs(y = "Proportion")
```


???

*reobtainable*: left, *undeniable*: right

---

layout: false

## Factorial design

**Two-by-two factorial design**

.center[

|    	    | B = B1     	| B = B2     	|
|-------- |--------	|--------	|
| **A = A1** 	| A1, B1 	| A1, B2 	|
| **A = A2** 	| A2, B1 	| A2, B2 	|

]

--

<br>

(Let's filter the data so we exclude the non-constituent cases)

|                        | Branching = left  | Branching = right  |
|------------------------|-------------------|--------------------|
| Relation = unrelated   | unrelated, left   | unrelated, right   |
| Relation = constituent | constituent, left | constituent, right |


--

<br>

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
How can we include **both predictors** in the model?
]

---

layout: true

## Multiple predictors

---

Last week's model with two dummy variables (for a three-level predictor):

<br>

.f3[
$$logit(p) = \beta_0 + (\beta_1 \cdot relation_{ncons}) + (\beta_2 \cdot relation_{cons})$$
]

---

Let's wrangle the data.

```{r setup-shallow, echo = TRUE}
shallow <- shallow %>% 
  filter(Relation_type != "NonConstituent") %>% 
  mutate(
    Relation_type = factor(Relation_type, levels = c("Unrelated", "Constituent")),
    Branching     = factor(Branching, levels = c("Left", "Right")),
    Accuracy      = factor(Accuracy, levels = c("incorrect", "correct"))
  )
```

---


```{r barplot-shallow}
# Manual recreation of proportions stacked bar chart (as basis for later)
(barplot_shallow <- shallow %>% 
  group_by(Relation_type, Branching) %>%
  summarise(correct = mean(ACC)) %>% 
  mutate(incorrect = 1 - correct) %>% 
  pivot_longer(correct:incorrect, names_to = 'Accuracy', values_to = 'propn') %>% 
  mutate(Accuracy = factor(Accuracy, levels = c('incorrect', 'correct'))) %>% 
  # gg the plot
  ggplot(aes(x = Relation_type, y = propn)) +
  geom_bar(stat = 'identity', aes(fill = Accuracy)) +
  facet_wrap(~ Branching, labeller = labeller(Branching = label_both)) +
  labs(y = 'Proportion',
       x = 'Relation type'))
```




---

|                        | Branching = left  | Branching = right  |
|------------------------|-------------------|--------------------|
| Relation = unrelated   | unrelated, left   | unrelated, right   |
| Relation = constituent | constituent, left | constituent, right |


--

<br>

| Relation_type 	| Branching 	|
|---------------	|-----------	|
| Unrelated     	| Left      	|
| Unrelated     	| Right     	|
| Constituent   	| Left      	|
| Constituent   	| Right     	|

---

<!-- my condolences to anyone trying to read this -->

| When: | Then coded as: |
| --- | --- |
| <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>Unrelated</td> <td>Left</td> </tr> <tr> <td>Unrelated</td> <td>Right</td> </tr> <tr> <td>Constituent</td> <td>Left</td> </tr> <tr> <td>Constituent</td> <td>Right</td> </tr> </tbody> </table> | <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0</td> </tr> <tr> <td>0</td> <td>1</td> </tr> <tr> <td>1</td> <td>0</td> </tr> <tr> <td>1</td> <td>1</td> </tr> </tbody> </table> |  

<!-- Here's how those two ensted tables look in markdown -->
<!-- | Relation_type 	| Branching 	| -->
<!-- |---------------	|-----------	| -->
<!-- | Unrelated     	| Left      	| -->
<!-- | Unrelated     	| Right     	| -->
<!-- | Constituent   	| Left      	| -->
<!-- | Constituent   	| Right     	| -->

<!-- | Relation_type 	| Branching 	| -->
<!-- |---------------	|-----------	| -->
<!-- | 0             	| 0         	| -->
<!-- | 0             	| 1         	| -->
<!-- | 1             	| 0         	| -->
<!-- | 1             	| 1         	| -->

<br>

--

Let's verify that this coding is what R will use:

.pull-left[
```{r contr1, echo=TRUE}
contrasts(shallow$Relation_type)
```
]

.pull-right[
```{r contr2, echo=TRUE}
contrasts(shallow$Branching)
```
]

---

| When: | Then coded as: |
| --- | --- |
| <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>Unrelated</td> <td>Left</td> </tr> <tr> <td>Unrelated</td> <td>Right</td> </tr> <tr> <td>Constituent</td> <td>Left</td> </tr> <tr> <td>Constituent</td> <td>Right</td> </tr> </tbody> </table> | <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0</td> </tr> <tr> <td>0</td> <td>1</td> </tr> <tr> <td>1</td> <td>0</td> </tr> <tr> <td>1</td> <td>1</td> </tr> </tbody> </table> | 
<br>

$$logit(p) = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch)$$
<br>

--

$$
\begin{aligned}
\text{Unrelated, Left:}     & & \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0)  &&= \beta_0  &\\
\text{Unrelated, Right:}    & & \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1)  &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   & & \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0)  &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  & & \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1)  &&= \beta_0 + \beta_1 + \beta_2 &\\
\end{aligned}
$$

---

$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 & \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 & \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}
$$

--

```{r mult-fit, echo=TRUE}
acc_mult_bm <- brm(
  Accuracy ~ Relation_type + Branching,
  family = bernoulli(),
  data   = shallow,
  backend = 'cmdstanr',
  file = 'data/cache/acc_mult_bm'
)
```

---

```{r mult-summary-full, echo=TRUE}
summary(acc_mult_bm)
```

---

```{r mult-summ-1a}
cat(capture.output(summary(acc_mult_bm))[8:12], sep = "\n")
```

--

<br>

.f4[
$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 & \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 & \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}
$$
]

---

```{r mult-summ-1b}
cat(capture.output(summary(acc_mult_bm))[8:12], sep = "\n")
```

<br>

.f4[
$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 & \sim Gaussian(1.08, 0.17) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 & \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}
$$
]

---

```{r mult-summ-2}
cat(capture.output(summary(acc_mult_bm))[8:12], sep = "\n")
```

<br>

.f4[
$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 & \sim Gaussian(1.08, 0.17) \\
\beta_1 & \sim Gaussian(0.69, 0.25) \\
\beta_2 & \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}
$$
]

---

```{r mult-summ-3}
cat(capture.output(summary(acc_mult_bm))[8:12], sep = "\n")
```

<br>

.f4[
$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 & \sim Gaussian(1.08, 0.17) \\
\beta_1 & \sim Gaussian(0.69, 0.25) \\
\beta_2 & \sim Gaussian(1.44, 0.27) \\
\end{aligned}
$$
]


---

layout: false
layout: true

## Conditional posterior probabilities

---

$$
\begin{aligned}
\text{Unrelated, Left:}     & & \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0)  &&= \beta_0  &\\
\text{Unrelated, Right:}    & & \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1)  &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   & & \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0)  &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  & & \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1)  &&= \beta_0 + \beta_1 + \beta_2 &\\
\end{aligned}
$$

<br>

--

From the model: mean $\beta_0 = 1.08$, mean $\beta_1 = 0.69$, and mean $\beta_2 = 1.44$.

<br>

--

$$
\begin{aligned}
\text{Unrelated, Left:}     & & 1.08 &+ (0.69 \cdot 0) + (1.44 \cdot 0)  &&= 1.08  &= 1.08 \text{ log-odds}\\
\text{Unrelated, Right:}    & & 1.08 &+ (0.69 \cdot 0) + (1.44 \cdot 1)  &&= 1.08 + 1.44 &= 2.52 \text{ log-odds}\\
\text{Constituent, Left:}   & & 1.08 &+ (0.69 \cdot 1) + (1.44 \cdot 0)  &&= 1.08 + 0.69 &= 1.77 \text{ log-odds}\\
\text{Constituent, Right:}  & & 1.08 &+ (0.69 \cdot 1) + (1.44 \cdot 1)  &&= 1.08 + 0.69 + 1.44 &= 3.21 \text{ log-odds}\\
\end{aligned}
$$

???

Ask: now, how move to probs?

---

```{r mult-draws}
mult_draws <- as_draws_df(acc_mult_bm)

# Compute conditional log-odds
mult_draws_long <- mult_draws %>% 
  mutate(
    Unrelated_Left  = b_Intercept,
    Unrelated_Right = b_Intercept + b_BranchingRight,
    Constituent_Left    = b_Intercept + b_Relation_typeConstituent,
    Constituent_Right   = b_Intercept + b_BranchingRight + b_Relation_typeConstituent
  ) %>% 
  select(Unrelated_Left:Constituent_Right) %>% 
  pivot_longer(everything(), names_to = 'pred_combo', values_to = 'logodds_samples') %>% 
  separate(pred_combo, into = c('Relation_type', 'Branching')) %>% 
  mutate(
    Relation_type = factor(Relation_type, levels = c('Unrelated', 'Constituent')),
    Branching     = factor(Branching, levels = c('Left', 'Right'))
  )
```


```{r mult-cri}
mult_cri <- mult_draws_long %>% 
  group_by(Relation_type, Branching) %>% 
  summarise(
    # Calculate the lower and upper bounds of a 95% CrI + mean
    q95_lo = round(quantile2(logodds_samples, probs = 0.025), 2),
    q95_hi = round(quantile2(logodds_samples, probs = 0.975), 2),
    mean_logodds = mean(logodds_samples),
    # Transform into probabilities
    p_q95_lo = round(plogis(q95_lo), 2),
    p_q95_hi = round(plogis(q95_hi), 2),
    p_mean   = round(plogis(mean_logodds), 2)
  )
```


```{r mult-draws-dens-lo}
mult_draws_long %>% 
  ggplot(aes(x = logodds_samples)) +
  geom_density(alpha = 0.5, aes(fill = Relation_type)) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  labs(x = "Log-odds",
       y = "Probability density",
       title = "Conditional posterior probability distributions\nof the log-odds of a 'correct' response",
       fill = "Relation type")
```

---

```{r mult-draws-dens-p}
(mult_draws_dens <- mult_draws_long %>% 
  ggplot(aes(x = plogis(logodds_samples))) +
  geom_density(alpha = 0.5, aes(fill = Relation_type)) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  xlim(0.5, 1) +
  labs(x = 'Probability',
       y = 'Probability density',
       title = "Conditional posterior probability distributions\nof the probability of a 'correct' response",
       fill = 'Relation type'))
```

---

```{r mult-draws-dens2}
mult_draws_dens +
  # intervals + means
  geom_point(data = mult_cri, aes(x = p_mean, 
                                  y=c(32, 32, 33, 33), 
                                  # colour=Relation_type,
                                  ), size=2) +
  geom_errorbar(data = mult_cri,
                aes(x = p_mean, 
                    y=c(32, 32, 33, 33), 
                    xmax = p_q95_hi, 
                    xmin = p_q95_lo, 
                    # colour=Relation_type
                    ),
                width = 0,
                size = 1)
```


---

layout: true

## Do these estimates match the data?

---

```{r barplot-shallow2}
barplot_shallow
```

---

```{r barplot-shallow-mult}
# Add in the model's estimates as points + error bars
(barplot_shallow_mult <- barplot_shallow +
  geom_point(data = mult_cri, aes(y = p_mean), size=2) +
  geom_errorbar(data = mult_cri,
                aes(y = p_mean, ymax = p_q95_hi, ymin = p_q95_lo),
                width = 0,
                size = 1))
```


???

The model assumes there's a difference in Branching = Right where there doesn't seem to be one.
And because that difference is small, it's also underestimating the larger difference in Branching = Left.

If only there were some way to tell the model that the effect of relation type can be different between the two levels of branching.

Oh wait...

---

layout: false
layout: true

## How does the current model fall short?

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
The question we want to answer: 
- **"Is the effect of `Relation_type` different when `Branching == Left` compared to when `Branching == Right`?"**
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
Our current model doesn't let effects differ between levels of other variables.
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
The solution: Include an **interaction** between these two predictors.
]

---

In other words: we want a **difference of differences**

```{r barplot-shallow3}
barplot_shallow
```

---

In other words: we want a **difference of differences**

```{r shallow-diffs}
shallow_endpts <- shallow %>% 
  group_by(Relation_type, Branching) %>%
  summarise(correct = mean(ACC)) %>% 
  pivot_wider(names_from = Relation_type, values_from = correct)

barplot_shallow +
  geom_segment(data = shallow_endpts, 
               size = 2,
               aes(y = Unrelated, yend = Constituent, x = 1.5, xend = 1.5))
```

---

layout: false
layout: true

## Including an interaction

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- Add an **interaction term** in the model.

- The interaction term gets its own beta coefficient.

- The estimate of the interaction beta coefficient tells us **how much one predictor's effect changes between levels of the other**.
]

---

$$logit(p) = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation \cdot branch)$$

| When: | Then coded as: |
| --- | --- |
| <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> </tr> </thead> <tbody> <tr> <td>Unrelated</td> <td>Left</td> </tr> <tr> <td>Unrelated</td> <td>Right</td> </tr> <tr> <td>Constituent</td> <td>Left</td> </tr> <tr> <td>Constituent</td> <td>Right</td> </tr> </tbody> </table> | <table> <thead> <tr> <th>Relation_type</th> <th>Branching</th> <th>Relation_type:Branching</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0</td> <td>0 \* 0 = 0</td> </tr> <tr> <td>0</td> <td>1</td> <td>0 \* 1 = 0</td> </tr> <tr> <td>1</td> <td>0</td> <td>1 \* 0 = 0</td> </tr> <tr> <td>1</td> <td>1</td> <td>1 \* 1 = 1</td> </tr> </tbody> </table>  |

--

$$
\begin{aligned}
\text{Unrelated, Left:}     && \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &&= \beta_0  &\\
\text{Unrelated, Right:}    && \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1) + (\beta_3 \cdot 0) &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   && \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  && \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1) &&= \beta_0 + \beta_1 + \beta_2 + \beta_3 &\\
\end{aligned}
$$

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
With both variables at their non-reference level (coded with 1) in a model **with no interaction:**

$$
 \beta_0 + (\beta_1 \cdot 1) + (\beta_2 \cdot 1) = \beta_0 + \beta_1 + \beta_2 \\
$$
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
And in a model **with an interaction:**

$$
\beta_0 + (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1 \cdot 1) = \beta_0 + \beta_1 + \beta_2 + \beta_3 \\
$$
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
$\beta_3$ **adjusts** the value of $\beta_1$ and $\beta_2$.

In other words, it **modulates the effect** of one predictor depending on the levels of the other.
]

---

```{r inter-fit, echo = TRUE}
acc_inter_bm <- brm(
  Accuracy ~ Relation_type + Branching + Relation_type:Branching,
  family = bernoulli(),
  data   = shallow,
  backend = 'cmdstanr',
  file = 'data/cache/acc_inter_bm'
)
```

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
A note on the syntax for specifying interactions in R:

**`Relation_type + Branching + Relation_type:Branching`**

is the same as

**`Relation_type * Branching`**

but more transparent about what's happening behind the scenes!
]

---

$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation \cdot branch)\\
\beta_0 & \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 & \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 & \sim Gaussian(\mu_2, \sigma_2) \\
\beta_3 & \sim Gaussian(\mu_3, \sigma_3) \\
\end{aligned}
$$

---

.f4[
```{r inter-summary, echo = TRUE}
summary(acc_inter_bm)
```
]

---

```{r inter-summ-1}
cat(capture.output(summary(acc_inter_bm))[8:13], sep = "\n")
```

<br>

$$
\begin{aligned}
\text{acc} & \sim Bernoulli(p) \\
logit(p) & = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation \cdot branch)\\
\beta_0 & \sim Gaussian(1.02, 0.17) \\
\beta_1 & \sim Gaussian(0.85, 0.29) \\
\beta_2 & \sim Gaussian(1.69, 0.36) \\
\beta_3 & \sim Gaussian(-0.63, 0.55) \\
\end{aligned}
$$

---

layout: false
layout: true

## Interpreting an interaction

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Interpretation 1:**

- $\beta_3$'s mean of $-0.63$ indicates an **average _negative_ adjustment to the effect of `Relation_type`** when we go from [branching = left] (the reference level) to [branching = right].

  - In other words, the model suggests that the effect of `Relation_type` is **on average smaller** in [branching = right] than in [branching = left] (the reference level).
  
  - **However**, the 95% CrI $[-1.72, 0.42]$ covers both negative and positive values, thus suggesting uncertainty about the sign and magnitude of the interaction.
]

--
  
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Equivalently, interpretation 2:**

- $\beta_3$'s mean indicates an **average _negative_ adjustment to the effect of `Branching`** when we go from [relation_type = unrelated] (reference level) to [relation_type = constituent].

  - Or: the model suggests that the effect of `Branching` is **on average smaller** in [relation_type = constituent] than in [relation_type = unrelated] (reference level). But the CrI suggests uncertainty.
]

---

.pull-left[
```{r barplot-symm1, out.width = "100%", fig.height=6}
shallow %>% 
  ggplot(aes(x = Relation_type, fill = Accuracy)) +
  geom_bar(position = 'fill') +
  facet_wrap(~ Branching, labeller = labeller(Branching = label_both)) +
  labs(y = 'Proportion',
       x = 'Relation type',
       title = 'Smaller effect of Relation_type in Branching = Right')
```
]

.pull-right[
```{r barplot-symm2, out.width = "100%", fig.height=6}
shallow %>% 
  ggplot(aes(x = Branching, fill = Accuracy)) +
  geom_bar(position = 'fill') +
  facet_wrap(~ Relation_type, labeller = labeller(Relation_type = label_both)) +
  labs(y = 'Proportion',
       x = 'Branching',
       title = "Smaller effect of Branching in Relation_type = Constituent")
```
]

---

layout: false
layout: true

## Conditional posterior probabilities

---

**Mean conditional posterior probabilities (log-odds)**

$$
\begin{aligned}
\text{Unrelated, Left:}     && \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &&= \beta_0  &\\
\text{Unrelated, Right:}    && \beta_0 &+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1) + (\beta_3 \cdot 0) &&= \beta_0 + \beta_2 &\\
\text{Constituent, Left:}   && \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &&= \beta_0 + \beta_1 &\\
\text{Constituent, Right:}  && \beta_0 &+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1) &&= \beta_0 + \beta_1 + \beta_2 + \beta_3 &\\
\end{aligned}
$$

--

<br>

From the model, the means are: $\beta_0 = 1.02$, $\beta_1 = 0.85$, $\beta_2 = 1.69$, and $\beta_3 = -0.63$.

$$
\begin{aligned}
\text{Unr., L:}     && 1.02 &+ (0.85 \cdot 0) + (1.69 \cdot 0) + (-0.63 \cdot 0) &&= 1.02  &= 1.02 \text{ log-odds}\\
\text{Unr., R:}    && 1.02 &+ (0.85 \cdot 0) + (1.69 \cdot 1) + (-0.63 \cdot 0) &&= 1.02 + 1.69 &= 2.71 \text{ log-odds}\\
\text{Con., L:}   && 1.02 &+ (0.85 \cdot 1) + (1.69 \cdot 0) + (-0.63 \cdot 0) &&= 1.02 + 0.85 &= 1.87 \text{ log-odds}\\
\text{Con., R:}  && 1.02 &+ (0.85 \cdot 1) + (1.69 \cdot 1) + (-0.63 \cdot 1) &&= 1.02 + 0.85 + 1.69 -0.63 &= 2.93 \text{ log-odds}\\
\end{aligned}
$$

---

```{r inter-draws}
inter_draws <- as_draws_df(acc_inter_bm)

# Compute conditional log-odds
inter_draws_long <- inter_draws %>% 
  mutate(
    Unrelated_Left  = b_Intercept,
    Unrelated_Right = b_Intercept + b_BranchingRight,
    Constituent_Left    = b_Intercept + b_Relation_typeConstituent,
    Constituent_Right   = b_Intercept + b_BranchingRight + b_Relation_typeConstituent + `b_Relation_typeConstituent:BranchingRight`
  ) %>% 
  select(Unrelated_Left:Constituent_Right) %>% 
  pivot_longer(everything(), names_to = 'pred_combo', values_to = 'logodds_samples') %>% 
  separate(pred_combo, into = c('Relation_type', 'Branching')) %>% 
  mutate(
    Relation_type = factor(Relation_type, levels = c('Unrelated', 'Constituent')),
    Branching     = factor(Branching, levels = c('Left', 'Right'))
  )
```


.pull-left[
```{r inter-draws-dens-1, out.width="100%"}
inter_draws_long %>% 
  ggplot(aes(x = logodds_samples, fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  labs(x = 'Log-odds',
       y = 'Probability density',
       title = 'Conditional posterior probability distributions\nof "correct" response',
       # subtitle = 'Model with interaction',
       fill = 'Relation type')
```
]

.pull-right[
```{r inter-draws-dens2, out.width="100%"}
inter_draws_long %>% 
  ggplot(aes(x = plogis(logodds_samples), fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  xlim(0, 1) +
  labs(x = 'Probability',
       y = 'Probability density',
       title = 'Conditional posterior probability distributions\nof "correct" response',
       # subtitle = 'Model with interaction',
       fill = 'Relation type')
```
]

---

**Log-odds of "correct" response**

.pull-left[
```{r mult-draws-dens-L-lo, fig.height=6, out.width="100%"}
mult_draws_long %>% 
  ggplot(aes(x = logodds_samples, fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  labs(x = 'Log-odds',
       y = 'Probability density',
       # title = 'Conditional posterior probability distributions\nof "correct" response',
       title = 'From a model without an interaction',
       fill = 'Relation type') +
  theme(legend.position = 'bottom')

```
]

.pull-right[
```{r inter-draws-dens-R-lo, fig.height=6, out.width="100%"}
inter_draws_long %>% 
  ggplot(aes(x = logodds_samples, fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  labs(x = 'Log-odds',
       y = 'Probability density',
       # title = 'Conditional posterior probability distributions\nof "correct" response',
       title = 'From a model with an interaction',
       fill = 'Relation type') +
  theme(legend.position = 'bottom')
```
]

---

**Probability of "correct" response**

.pull-left[
```{r mult-draws-dens-L, fig.height=6, out.width="100%"}
mult_draws_long %>% 
  ggplot(aes(x = plogis(logodds_samples), fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  xlim(0, 1) +
  labs(x = 'Probability',
       y = 'Probability density',
       # title = 'Conditional posterior probability distributions\nof "correct" response',
       title = 'From a model without an interaction',
       fill = 'Relation type') +
  theme(legend.position = 'bottom')

```
]

.pull-right[
```{r inter-draws-dens-R, fig.height=6, out.width="100%"}
inter_draws_long %>% 
  ggplot(aes(x = plogis(logodds_samples), fill = Relation_type)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Branching, nrow=2, labeller = labeller(Branching = label_both)) +
  xlim(0, 1) +
  labs(x = 'Probability',
       y = 'Probability density',
       # title = 'Conditional posterior probability distributions\nof "correct" response',
       title = 'From a model with an interaction',
       fill = 'Relation type') +
  theme(legend.position = 'bottom') +
  ylim(0, 40)


```
]

---

```{r inter-cri}
inter_cri <- inter_draws_long %>% 
  group_by(Relation_type, Branching) %>% 
  summarise(
    # Calculate the lower and upper bounds of a 95% CrI + mean
    q95_lo = round(quantile2(logodds_samples, probs = 0.025), 2),
    q95_hi = round(quantile2(logodds_samples, probs = 0.975), 2),
    mean_logodds = mean(logodds_samples),
    # Transform into probabilities
    p_q95_lo = round(plogis(q95_lo), 2),
    p_q95_hi = round(plogis(q95_hi), 2),
    p_mean   = round(plogis(mean_logodds), 2)
  )
```

```{r barplot-shallow-inter}
# Add in the model's estimates as points + error bars
barplot_shallow_inter <- barplot_shallow +
  geom_point(data = inter_cri, aes(y = p_mean), size=2) +
  geom_errorbar(data = inter_cri,
                aes(y = p_mean, ymax = p_q95_hi, ymin = p_q95_lo),
                width = 0,
                size = 1) +
  NULL
```

.pull-left[
```{r mult-barplot-L, out.width="100%"}
barplot_shallow_mult +
  labs(title = 'Without interaction')
```
]

.pull-right[
```{r inter-barplot-R, out.width="100%"}
barplot_shallow_inter +
  labs(title = 'With interaction')
```
]

---

layout: false

## Reporting

> We fitted a Bayesian linear model with response accuracy as the outcome variable, using a Bernoulli distribution as the distribution family of the outcome. We included the following predictors: prime relation type (unrelated vs constituent), branching (left vs right), and an interaction between the two. The predictors were coded using the default treatment contrasts and the reference level was set to the first level as indicated here.
>
> According to the model, we can be 95% confident that the probability of obtaining a correct response is between 67 and 80% when the relation type is unrelated and the word pair is left-branching ($\beta$ = 1.02, SD = 0.17, 95% CrI [0.69, 1.38]). When the relation type is unrelated and the word pair is right-branching, the probability of a correct response is between 90 and 97%, at 95% confidence ($\beta$ = 1.69, SD = 0.36, 95% CrI [1.04, 2.42]). Turning to the constituent relation type, the model suggests a probability of a correct response between 81 and 91% ($\beta$ = 0.85, SD = 0.29, 95% CrI [0.28, 1.43]). When the relation type is constituent and the word pair is right-branching, we can be 95% confident that the probability of a correct response is between 91 and 97% ($\beta$ = -0.63, SD = 0.55, 95% CrI [-1.72, 0.42]).
>
> As suggested by the 95% CrI of the interaction term (in log-odds [-1.72, 0.42]), there is quite a lot of uncertainty as to whether the difference in probability of correct response in unrelated vs constituent in right-branching pairs differs from that in left-branching pairs, since the interval covers both negative and positive values. Moreover, the conditional posterior probabilities of unrelated and right-branching on the one hand and constituent and right branching on the other are very similar, as can be seen in the plot above (and as suggested by the respective 95% CrIs: 90-97% vs 91-97% respectively).

---

## Summary

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- The factorial design of a study is a tabular representation of the combination of variables and levels employed in a study.

- We can fit a model that contains an **interaction term** between multiple predictors when we want to allow the effect of one predictor to possibly differ depending on the levels of the other predictors. It is a good idea to always include interactions.

- The interaction term's $\beta$ tells us **how much one predictor's effect changes between the reference and non-reference levels of the other**.
]

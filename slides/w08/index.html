<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Quantitative Methods for LEL</title>
    <meta charset="utf-8" />
    <meta name="author" content="Stefano Coretta and Elizabeth Pankratz" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/freezeframe/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <link rel="stylesheet" href="../xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="../custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Quantitative Methods for LEL
]
.subtitle[
## Week 8 - Multiple predictors and interactions
]
.author[
### Stefano Coretta and Elizabeth Pankratz
]
.institute[
### University of Edinburgh
]
.date[
### 2023/11/07
]

---






## Summary from last week

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- **Binary outcomes** are outcome variables with two discrete levels (e.g., yes/no, grammatical/ungrammatical, correct/incorrect).

- We can visualise binary outcomes as **proportions**.

- Binary outcomes follow the Bernoulli distribution which has one parameter, `\(p\)`, the probability of "success" (`family = bernoulli()`).

- A Bernoulli model returns estimates in log-odds. We can convert log-odds into probabilities with the logistic function (`plogis()`).

- A Bayesian Credible Interval (CrI) tells you the region in which, with some probability (like 95%, 60%, 73%, etc), the true value lies.
]

---

&lt;iframe allowfullscreen frameborder="0" height="100%" mozallowfullscreen style="min-width: 500px; min-height: 355px" src="https://app.wooclap.com/events/SQQFXB/questions/65436cf3c1a55c4249b6d94e" width="100%"&gt;&lt;/iframe&gt;

---

layout: true

## The `shallow` data: Relation type and Branching

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Lexical decision task:** Is the string you see a word in English or not?

- Outcome variable: **Accuracy** (incorrect vs correct).

- Predictors: 

  - **Relation_type**: unrelated, non-constituent, constituent.
  
  - **Branching**: left ([[un-[ripe]]-ness]), right ([un-[[grace]-ful]]).
]

---


```
## # A tibble: 865 × 5
##    Group ID    Accuracy  Relation_type  Branching
##    &lt;chr&gt; &lt;chr&gt; &lt;fct&gt;     &lt;chr&gt;          &lt;chr&gt;    
##  1 L1    L1_01 correct   Unrelated      Left     
##  2 L1    L1_01 correct   Constituent    Left     
##  3 L1    L1_01 correct   Unrelated      Left     
##  4 L1    L1_01 correct   Constituent    Left     
##  5 L1    L1_01 incorrect Unrelated      Left     
##  6 L1    L1_01 correct   Unrelated      Right    
##  7 L1    L1_01 correct   Constituent    Right    
##  8 L1    L1_01 correct   NonConstituent Left     
##  9 L1    L1_01 correct   NonConstituent Left     
## 10 L1    L1_01 correct   Constituent    Left     
## # ℹ 855 more rows
```

---

&lt;img src="index_files/figure-html/shallow-plot-1.png" width="60%" style="display: block; margin: auto;" /&gt;


???

*reobtainable*: left, *undeniable*: right

---

layout: false

## Factorial design

**Two-by-two factorial design**

.center[

|    	    | B = B1     	| B = B2     	|
|-------- |--------	|--------	|
| **A = A1** 	| A1, B1 	| A1, B2 	|
| **A = A2** 	| A2, B1 	| A2, B2 	|

]

--

&lt;br&gt;

(Let's filter the data so we exclude the non-constituent cases)

|                        | Branching = left  | Branching = right  |
|------------------------|-------------------|--------------------|
| Relation = unrelated   | unrelated, left   | unrelated, right   |
| Relation = constituent | constituent, left | constituent, right |


--

&lt;br&gt;

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
How can we include **both predictors** in the model?
]

---

layout: true

## Multiple predictors

---

Last week's model with two dummy variables (for a three-level predictor):

&lt;br&gt;

.f3[
`$$logit(p) = \beta_0 + (\beta_1 \cdot relation_{ncons}) + (\beta_2 \cdot relation_{cons})$$`
]

---

Let's wrangle the data.


```r
shallow &lt;- shallow %&gt;% 
  filter(Relation_type != "NonConstituent") %&gt;% 
  mutate(
    Relation_type = factor(Relation_type, levels = c("Unrelated", "Constituent")),
    Branching     = factor(Branching, levels = c("Left", "Right")),
    Accuracy      = factor(Accuracy, levels = c("incorrect", "correct"))
  )
```

---


&lt;img src="index_files/figure-html/barplot-shallow-1.png" width="60%" style="display: block; margin: auto;" /&gt;




---

|                        | Branching = left  | Branching = right  |
|------------------------|-------------------|--------------------|
| Relation = unrelated   | unrelated, left   | unrelated, right   |
| Relation = constituent | constituent, left | constituent, right |


--

&lt;br&gt;

| Relation_type 	| Branching 	|
|---------------	|-----------	|
| Unrelated     	| Left      	|
| Unrelated     	| Right     	|
| Constituent   	| Left      	|
| Constituent   	| Right     	|

---

&lt;!-- my condolences to anyone trying to read this --&gt;

| When: | Then coded as: |
| --- | --- |
| &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Relation_type&lt;/th&gt; &lt;th&gt;Branching&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Unrelated&lt;/td&gt; &lt;td&gt;Left&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Unrelated&lt;/td&gt; &lt;td&gt;Right&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Constituent&lt;/td&gt; &lt;td&gt;Left&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Constituent&lt;/td&gt; &lt;td&gt;Right&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; | &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Relation_type&lt;/th&gt; &lt;th&gt;Branching&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; |  

&lt;!-- Here's how those two ensted tables look in markdown --&gt;
&lt;!-- | Relation_type 	| Branching 	| --&gt;
&lt;!-- |---------------	|-----------	| --&gt;
&lt;!-- | Unrelated     	| Left      	| --&gt;
&lt;!-- | Unrelated     	| Right     	| --&gt;
&lt;!-- | Constituent   	| Left      	| --&gt;
&lt;!-- | Constituent   	| Right     	| --&gt;

&lt;!-- | Relation_type 	| Branching 	| --&gt;
&lt;!-- |---------------	|-----------	| --&gt;
&lt;!-- | 0             	| 0         	| --&gt;
&lt;!-- | 0             	| 1         	| --&gt;
&lt;!-- | 1             	| 0         	| --&gt;
&lt;!-- | 1             	| 1         	| --&gt;

&lt;br&gt;

--

Let's verify that this coding is what R will use:

.pull-left[

```r
contrasts(shallow$Relation_type)
```

```
##             Constituent
## Unrelated             0
## Constituent           1
```
]

.pull-right[

```r
contrasts(shallow$Branching)
```

```
##       Right
## Left      0
## Right     1
```
]

---

| When: | Then coded as: |
| --- | --- |
| &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Relation_type&lt;/th&gt; &lt;th&gt;Branching&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Unrelated&lt;/td&gt; &lt;td&gt;Left&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Unrelated&lt;/td&gt; &lt;td&gt;Right&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Constituent&lt;/td&gt; &lt;td&gt;Left&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Constituent&lt;/td&gt; &lt;td&gt;Right&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; | &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Relation_type&lt;/th&gt; &lt;th&gt;Branching&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; | 
&lt;br&gt;

`$$logit(p) = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch)$$`
&lt;br&gt;

--

$$
`\begin{aligned}
\text{Unrelated, Left:}     &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0)  &amp;&amp;= \beta_0  &amp;\\
\text{Unrelated, Right:}    &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1)  &amp;&amp;= \beta_0 + \beta_2 &amp;\\
\text{Constituent, Left:}   &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0)  &amp;&amp;= \beta_0 + \beta_1 &amp;\\
\text{Constituent, Right:}  &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1)  &amp;&amp;= \beta_0 + \beta_1 + \beta_2 &amp;\\
\end{aligned}`
$$

---

$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 &amp; \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 &amp; \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 &amp; \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}`
$$

--


```r
acc_mult_bm &lt;- brm(
  Accuracy ~ Relation_type + Branching,
  family = bernoulli(),
  data   = shallow,
  backend = 'cmdstanr',
  file = 'data/cache/acc_mult_bm'
)
```

---


```r
summary(acc_mult_bm)
```

```
##  Family: bernoulli 
##   Links: mu = logit 
## Formula: Accuracy ~ Relation_type + Branching 
##    Data: shallow (Number of observations: 692) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    1.08      0.17     0.75     1.43 1.00     4499
## Relation_typeConstituent     0.69      0.25     0.20     1.17 1.00     2877
## BranchingRight               1.44      0.27     0.91     1.99 1.00     2465
##                          Tail_ESS
## Intercept                    3212
## Relation_typeConstituent     2567
## BranchingRight               2441
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

---


```
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    1.08      0.17     0.75     1.43 1.00     4499
## Relation_typeConstituent     0.69      0.25     0.20     1.17 1.00     2877
## BranchingRight               1.44      0.27     0.91     1.99 1.00     2465
```

--

&lt;br&gt;

.f4[
$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 &amp; \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 &amp; \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 &amp; \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}`
$$
]

---


```
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    1.08      0.17     0.75     1.43 1.00     4499
## Relation_typeConstituent     0.69      0.25     0.20     1.17 1.00     2877
## BranchingRight               1.44      0.27     0.91     1.99 1.00     2465
```

&lt;br&gt;

.f4[
$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 &amp; \sim Gaussian(1.08, 0.17) \\
\beta_1 &amp; \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 &amp; \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}`
$$
]

---


```
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    1.08      0.17     0.75     1.43 1.00     4499
## Relation_typeConstituent     0.69      0.25     0.20     1.17 1.00     2877
## BranchingRight               1.44      0.27     0.91     1.99 1.00     2465
```

&lt;br&gt;

.f4[
$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 &amp; \sim Gaussian(1.08, 0.17) \\
\beta_1 &amp; \sim Gaussian(0.69, 0.25) \\
\beta_2 &amp; \sim Gaussian(\mu_2, \sigma_2) \\
\end{aligned}`
$$
]

---


```
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    1.08      0.17     0.75     1.43 1.00     4499
## Relation_typeConstituent     0.69      0.25     0.20     1.17 1.00     2877
## BranchingRight               1.44      0.27     0.91     1.99 1.00     2465
```

&lt;br&gt;

.f4[
$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + \beta_1 \cdot relation + \beta_2 \cdot branch \\
\beta_0 &amp; \sim Gaussian(1.08, 0.17) \\
\beta_1 &amp; \sim Gaussian(0.69, 0.25) \\
\beta_2 &amp; \sim Gaussian(1.44, 0.27) \\
\end{aligned}`
$$
]


---

layout: false
layout: true

## Conditional posterior probabilities

---

$$
`\begin{aligned}
\text{Unrelated, Left:}     &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0)  &amp;&amp;= \beta_0  &amp;\\
\text{Unrelated, Right:}    &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1)  &amp;&amp;= \beta_0 + \beta_2 &amp;\\
\text{Constituent, Left:}   &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0)  &amp;&amp;= \beta_0 + \beta_1 &amp;\\
\text{Constituent, Right:}  &amp; &amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1)  &amp;&amp;= \beta_0 + \beta_1 + \beta_2 &amp;\\
\end{aligned}`
$$

&lt;br&gt;

--

From the model: mean `\(\beta_0 = 1.08\)`, mean `\(\beta_1 = 0.69\)`, and mean `\(\beta_2 = 1.44\)`.

&lt;br&gt;

--

$$
`\begin{aligned}
\text{Unrelated, Left:}     &amp; &amp; 1.08 &amp;+ (0.69 \cdot 0) + (1.44 \cdot 0)  &amp;&amp;= 1.08  &amp;= 1.08 \text{ log-odds}\\
\text{Unrelated, Right:}    &amp; &amp; 1.08 &amp;+ (0.69 \cdot 0) + (1.44 \cdot 1)  &amp;&amp;= 1.08 + 1.44 &amp;= 2.52 \text{ log-odds}\\
\text{Constituent, Left:}   &amp; &amp; 1.08 &amp;+ (0.69 \cdot 1) + (1.44 \cdot 0)  &amp;&amp;= 1.08 + 0.69 &amp;= 1.77 \text{ log-odds}\\
\text{Constituent, Right:}  &amp; &amp; 1.08 &amp;+ (0.69 \cdot 1) + (1.44 \cdot 1)  &amp;&amp;= 1.08 + 0.69 + 1.44 &amp;= 3.21 \text{ log-odds}\\
\end{aligned}`
$$

???

Ask: now, how move to probs?

---







&lt;img src="index_files/figure-html/mult-draws-dens-lo-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/mult-draws-dens-p-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/mult-draws-dens2-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---

layout: true

## Do these estimates match the data?

---

&lt;img src="index_files/figure-html/barplot-shallow2-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="index_files/figure-html/barplot-shallow-mult-1.png" width="60%" style="display: block; margin: auto;" /&gt;


???

The model assumes there's a difference in Branching = Right where there doesn't seem to be one.
And because that difference is small, it's also underestimating the larger difference in Branching = Left.

If only there were some way to tell the model that the effect of relation type can be different between the two levels of branching.

Oh wait...

---

layout: false
layout: true

## How does the current model fall short?

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
The question we want to answer: 
- **"Is the effect of `Relation_type` different when `Branching == Left` compared to when `Branching == Right`?"**
]

--

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
Our current model doesn't let effects differ between levels of other variables.
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
The solution: Include an **interaction** between these two predictors.
]

---

In other words: we want a **difference of differences**

&lt;img src="index_files/figure-html/barplot-shallow3-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

In other words: we want a **difference of differences**

&lt;img src="index_files/figure-html/shallow-diffs-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

layout: false
layout: true

## Including an interaction

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- Add an **interaction term** in the model.

- The interaction term gets its own beta coefficient.

- The estimate of the interaction beta coefficient tells us **how much one predictor's effect changes between levels of the other**.
]

---

`$$logit(p) = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation \cdot branch)$$`

| When: | Then coded as: |
| --- | --- |
| &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Relation_type&lt;/th&gt; &lt;th&gt;Branching&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Unrelated&lt;/td&gt; &lt;td&gt;Left&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Unrelated&lt;/td&gt; &lt;td&gt;Right&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Constituent&lt;/td&gt; &lt;td&gt;Left&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Constituent&lt;/td&gt; &lt;td&gt;Right&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; | &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Relation_type&lt;/th&gt; &lt;th&gt;Branching&lt;/th&gt; &lt;th&gt;Relation_type:Branching&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;0 \* 0 = 0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;0 \* 1 = 0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;0&lt;/td&gt; &lt;td&gt;1 \* 0 = 0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;1 \* 1 = 1&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt;  |

--

$$
`\begin{aligned}
\text{Unrelated, Left:}     &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &amp;&amp;= \beta_0  &amp;\\
\text{Unrelated, Right:}    &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1) + (\beta_3 \cdot 0) &amp;&amp;= \beta_0 + \beta_2 &amp;\\
\text{Constituent, Left:}   &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &amp;&amp;= \beta_0 + \beta_1 &amp;\\
\text{Constituent, Right:}  &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1) &amp;&amp;= \beta_0 + \beta_1 + \beta_2 + \beta_3 &amp;\\
\end{aligned}`
$$

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
With both variables at their non-reference level (coded with 1) in a model **with no interaction:**

$$
 \beta_0 + (\beta_1 \cdot 1) + (\beta_2 \cdot 1) = \beta_0 + \beta_1 + \beta_2 \\
$$
]

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
And in a model **with an interaction:**

$$
\beta_0 + (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1 \cdot 1) = \beta_0 + \beta_1 + \beta_2 + \beta_3 \\
$$
]

--

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt2[
`\(\beta_3\)` **adjusts** the value of `\(\beta_1\)` and `\(\beta_2\)`.

In other words, it **modulates the effect** of one predictor depending on the levels of the other.
]

---


```r
acc_inter_bm &lt;- brm(
  Accuracy ~ Relation_type + Branching + Relation_type:Branching,
  family = bernoulli(),
  data   = shallow,
  backend = 'cmdstanr',
  file = 'data/cache/acc_inter_bm'
)
```

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
A note on the syntax for specifying interactions in R:

**`Relation_type + Branching + Relation_type:Branching`**

is the same as

**`Relation_type * Branching`**

but more transparent about what's happening behind the scenes!
]

---

$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation \cdot branch)\\
\beta_0 &amp; \sim Gaussian(\mu_0, \sigma_0) \\
\beta_1 &amp; \sim Gaussian(\mu_1, \sigma_1) \\
\beta_2 &amp; \sim Gaussian(\mu_2, \sigma_2) \\
\beta_3 &amp; \sim Gaussian(\mu_3, \sigma_3) \\
\end{aligned}`
$$

---

.f4[

```r
summary(acc_inter_bm)
```

```
##  Family: bernoulli 
##   Links: mu = logit 
## Formula: Accuracy ~ Relation_type + Branching + Relation_type:Branching 
##    Data: shallow (Number of observations: 692) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##                                         Estimate Est.Error l-95% CI u-95% CI
## Intercept                                   1.02      0.17     0.69     1.38
## Relation_typeConstituent                    0.85      0.29     0.28     1.43
## BranchingRight                              1.69      0.36     1.04     2.42
## Relation_typeConstituent:BranchingRight    -0.63      0.55    -1.72     0.42
##                                         Rhat Bulk_ESS Tail_ESS
## Intercept                               1.00     3445     3109
## Relation_typeConstituent                1.00     2527     2141
## BranchingRight                          1.00     2131     2325
## Relation_typeConstituent:BranchingRight 1.00     1860     2203
## 
## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).
```
]

---


```
## Population-Level Effects: 
##                                         Estimate Est.Error l-95% CI u-95% CI
## Intercept                                   1.02      0.17     0.69     1.38
## Relation_typeConstituent                    0.85      0.29     0.28     1.43
## BranchingRight                              1.69      0.36     1.04     2.42
## Relation_typeConstituent:BranchingRight    -0.63      0.55    -1.72     0.42
```

&lt;br&gt;

$$
`\begin{aligned}
\text{acc} &amp; \sim Bernoulli(p) \\
logit(p) &amp; = \beta_0 + (\beta_1 \cdot relation) + (\beta_2 \cdot branch) + (\beta_3 \cdot relation \cdot branch)\\
\beta_0 &amp; \sim Gaussian(1.02, 0.17) \\
\beta_1 &amp; \sim Gaussian(0.85, 0.29) \\
\beta_2 &amp; \sim Gaussian(1.69, 0.36) \\
\beta_3 &amp; \sim Gaussian(-0.63, 0.55) \\
\end{aligned}`
$$

---

layout: false
layout: true

## Interpreting an interaction

---

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Interpretation 1:**

- `\(\beta_3\)`'s mean of `\(-0.63\)` indicates an **average _negative_ adjustment to the effect of `Relation_type`** when we go from [branching = left] (the reference level) to [branching = right].

  - In other words, the model suggests that the effect of `Relation_type` is **on average smaller** in [branching = right] than in [branching = left] (the reference level).
  
  - **However**, the 95% CrI `\([-1.72, 0.42]\)` covers both negative and positive values, thus suggesting uncertainty about the sign and magnitude of the interaction.
]

--
  
.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
**Equivalently, interpretation 2:**

- `\(\beta_3\)`'s mean indicates an **average _negative_ adjustment to the effect of `Branching`** when we go from [relation_type = unrelated] (reference level) to [relation_type = constituent].

  - Or: the model suggests that the effect of `Branching` is **on average smaller** in [relation_type = constituent] than in [relation_type = unrelated] (reference level). But the CrI suggests uncertainty.
]

---

.pull-left[
&lt;img src="index_files/figure-html/barplot-symm1-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="index_files/figure-html/barplot-symm2-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---

layout: false
layout: true

## Conditional posterior probabilities

---

**Mean conditional posterior probabilities (log-odds)**

$$
`\begin{aligned}
\text{Unrelated, Left:}     &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &amp;&amp;= \beta_0  &amp;\\
\text{Unrelated, Right:}    &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 0) + (\beta_2 \cdot 1) + (\beta_3 \cdot 0) &amp;&amp;= \beta_0 + \beta_2 &amp;\\
\text{Constituent, Left:}   &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 0) + (\beta_3 \cdot 0) &amp;&amp;= \beta_0 + \beta_1 &amp;\\
\text{Constituent, Right:}  &amp;&amp; \beta_0 &amp;+ (\beta_1 \cdot 1) + (\beta_2 \cdot 1) + (\beta_3 \cdot 1) &amp;&amp;= \beta_0 + \beta_1 + \beta_2 + \beta_3 &amp;\\
\end{aligned}`
$$

--

&lt;br&gt;

From the model, the means are: `\(\beta_0 = 1.02\)`, `\(\beta_1 = 0.85\)`, `\(\beta_2 = 1.69\)`, and `\(\beta_3 = -0.63\)`.

$$
`\begin{aligned}
\text{Unr., L:}     &amp;&amp; 1.02 &amp;+ (0.85 \cdot 0) + (1.69 \cdot 0) + (-0.63 \cdot 0) &amp;&amp;= 1.02  &amp;= 1.02 \text{ log-odds}\\
\text{Unr., R:}    &amp;&amp; 1.02 &amp;+ (0.85 \cdot 0) + (1.69 \cdot 1) + (-0.63 \cdot 0) &amp;&amp;= 1.02 + 1.69 &amp;= 2.71 \text{ log-odds}\\
\text{Con., L:}   &amp;&amp; 1.02 &amp;+ (0.85 \cdot 1) + (1.69 \cdot 0) + (-0.63 \cdot 0) &amp;&amp;= 1.02 + 0.85 &amp;= 1.87 \text{ log-odds}\\
\text{Con., R:}  &amp;&amp; 1.02 &amp;+ (0.85 \cdot 1) + (1.69 \cdot 1) + (-0.63 \cdot 1) &amp;&amp;= 1.02 + 0.85 + 1.69 -0.63 &amp;= 2.93 \text{ log-odds}\\
\end{aligned}`
$$

---




.pull-left[
&lt;img src="index_files/figure-html/inter-draws-dens-1-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="index_files/figure-html/inter-draws-dens2-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---

**Log-odds of "correct" response**

.pull-left[
&lt;img src="index_files/figure-html/mult-draws-dens-L-lo-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="index_files/figure-html/inter-draws-dens-R-lo-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---

**Probability of "correct" response**

.pull-left[
&lt;img src="index_files/figure-html/mult-draws-dens-L-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="index_files/figure-html/inter-draws-dens-R-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---





.pull-left[
&lt;img src="index_files/figure-html/mult-barplot-L-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="index_files/figure-html/inter-barplot-R-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---

layout: false

## Reporting

&gt; We fitted a Bayesian linear model with response accuracy as the outcome variable, using a Bernoulli distribution as the distribution family of the outcome. We included the following predictors: prime relation type (unrelated vs constituent), branching (left vs right), and an interaction between the two. The predictors were coded using the default treatment contrasts and the reference level was set to the first level as indicated here.
&gt;
&gt; According to the model, we can be 95% confident that the probability of obtaining a correct response is between 67 and 80% when the relation type is unrelated and the word pair is left-branching ($\beta$ = 1.02, SD = 0.17, 95% CrI [0.69, 1.38]). When the relation type is unrelated and the word pair is right-branching, the probability of a correct response is between 90 and 97%, at 95% confidence ($\beta$ = 1.69, SD = 0.36, 95% CrI [1.04, 2.42]). Turning to the constituent relation type, the model suggests a probability of a correct response between 81 and 91% ($\beta$ = 0.85, SD = 0.29, 95% CrI [0.28, 1.43]). When the relation type is constituent and the word pair is right-branching, we can be 95% confident that the probability of a correct response is between 91 and 97% ($\beta$ = -0.63, SD = 0.55, 95% CrI [-1.72, 0.42]).
&gt;
&gt; As suggested by the 95% CrI of the interaction term (in log-odds [-1.72, 0.42]) for constituent relation type and right-branching pairs, there is quite a lot of uncertainty in relation to the difference in probability of correct response in unrelated vs constituent in right-branching pairs, since the interval covers both negative and positive values. Moreover, the conditional posterior probabilities of unrelated and right-branching on the one hand and constituent and right branching on the other are very similar, as can be seen in the plot above (and as suggested by the respective 95% CrIs: 90-97% vs 91-97% respectively).

---

## Summary

.bg-washed-blue.b--dark-blue.ba.bw2.br3.shadow-5.ph4.mt2[
- The factorial design of a study is a tabular representation of the combination of variables and levels employed in a study.

- We can fit a model that contains an **interaction term** between multiple predictors when we want to allow the effect of one predictor to possibly differ depending on the levels of the other predictors. It is a good idea to always include interactions.

- The interaction term's `\(\beta\)` tells us **how much one predictor's effect changes between the reference and non-reference levels of the other**.
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="../macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

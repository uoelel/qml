---
title: "Regression: Indexing of categorical predictors"
description: "Learn about indexing of categorical predictors in regression models"
author: "Stefano Coretta"
date: 2024-06-25
---

::: callout-warning
## Prerequisites

- [Introduction to regression models (Part III): include categorical predictors](posts/intro-regression-categorical.qmd).
:::

## Categorical predictors: contrasts vs indexing

Categorical predictors in regression models are coded by default using the so-called "treatment" contrasts, a type of contrast coding.

This means that the intercept of the model will correspond to the predicted value when the categorical predictor is at the reference level, and the other coefficients will be the *difference* between the predicted value when the categorical predictor is at the other levels and the intercept.


This way of coding categorical predictors makes it more difficult to set up priors and can at times make it less straightforward to interpret the model summary.

In this post, you will learn about a different method of coding categorical predictors, called **indexing**.

With this method, the model estimates the predicted value for each level of the predictor, rather than for just the reference level. This means that you don't get coefficients that are differences between predicted values at different levels.

Let's see an example of both methods using data from Coretta 2018.

## The data

```{r}
#| label: data
# Install the coretta2018itapol package first if needed.
# remotes::install_github("stefanocoretta/coretta2018itapol")
library(coretta2018itapol)
data("token_measures")
```

Here's a preview of the data.

```{r}
# Let's remove NAs from the v1_duration column
library(tidyverse)
token_measures <- token_measures |> 
  drop_na(v1_duration)

token_measures
```


## Treatment contrasts

```{r}
library(brms)
get_prior(
  v1_duration ~ c2_phonation,
  family = lognormal,
  data = token_measures,
)
```

We get an `Intercept` (that's the expected vowel duration when the following consonant is voiced) and a `class = b` prior for the coefficient `c2_phonationvoiceless`. The coefficient `c2_phonationvoiceless` is the *difference* between the vowel duration when the following consonant is voiceless and the vowel duration when the following consonant is voiced.

$$
\begin{align}
vdur & \sim LogNormal(\mu, \sigma) \\
\mu & = \beta_0 + \beta_1 \cdot \text{voiceless}
\end{align}
$$

where $\text{voiceless}$ is an "indicator" (aka dummy) variable that "turns on" the $\beta_1$ coefficient in the formula of $\mu$ when the following consonant is voiceless.

Hence why $\beta_1$ is a difference between expected values (the value when C2 is voiceless - the value when C2 is voiced).

Setting priors on $\beta_0$ and $\beta_1$ means we need to think about:

- What we expect the mean value duration to be when C2 is voiced, and
- What we expect the *difference* in mean between vowels followed by a voiceless vs voiced consonant.

It is much easier to set priors on the mean value duration when C2 is voiced and when C2 is voiceless. We can use indexing to achieve that.

## Indexing

With **indexing**, each level in a categorical predictor gets it's own coefficient and the model estimates the predicted value of the outcome at each level.

Differently from setting contrasts with `contrasts()<-`, indexing is applied by *suppressing the intercept* of the model with `0 +`.

```{r}
get_prior(
  v1_duration ~ 0 + c2_phonation,
  family = lognormal,
  data = token_measures,
)
```

You can see that there is no `class = Intercept` in the output of `get_prior()` because we "suppressed" the intercept of the model.

Now, `c2_phonationvoiced` is the mean vowel duration when the following consonant is voiced and `c2_phonationvoiceless` is the mean vowel duration when the following consonant is voiceless.

## Fitting a model with indexing

```{r}
m_i <- brm(
  v1_duration ~ 0 + c2_phonation,
  family = lognormal,
  data = token_measures,
  seed = 1425,
  file = "data/cache/regression-indexing-m_i"
)
```

```{r}
summary(m_i)
```

## Get the difference between levels

We can now quickly calculate the difference between `c2_phonationvoiced` and `c2_phonationvoiceless` with the `avg_comparisons()` function from the [marginaleffects](https://marginaleffects.com) package.

```{r}
#| label: m-i-diff
library(marginaleffects)
# you will also have to install the collapse package

avg_comparisons(m_i, variables = "c2_phonation")
```

So based on the model and data, vowels followed by voiceless consonants are 7-14.5 ms shorter than vowels followed by voiced stops, at 95% probability.

---
title: "Poisson regression: count"
description: "Learn how to fit Poisson regressions for count data"
author: ["Stefano Coretta"]
date: 2024-09-12
execute: 
  freeze: auto
draft: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
theme_set(theme_light())
library(brms)
```

::: callout-warning
## Prerequisites

-   [Regression: binary outcome variables](regression-bernoulli.qmd).
:::

## Count data and the Poisson family

**Count data** is another common type of variable in linguistics. Corpus linguistics in particular usually has count variables, like number of relative clauses or number of direct vs indirect objects to mark the beneficiary.

When modelling count data, the researcher is usually interested in the count themselves. In other cases, they might be interested in the relative counts (proportion) out of a million words or the like (depending on the size of the corpus).

The distribution family for count data is the **Poisson family**. The Poisson family has only one parameter, $\lambda$, which is also known as the "rate". Higher values of $\lambda$ correspond to greater counts.

Like with Bernoulli models, there is a catch: counts are discrete numeric variables that can only be positive, i.e. they are bounded. Regression models don't work well with bounded variables (we have seen this for probabilities), so we need to apply a transformation as we did in Bernoulli models.

The transformation used in Poisson models is the (natural) logarithm. The inverse of the logarithm is the exponential function.

```{r}
#| label: log-exp

log_15 <- log(15)
log_15

log_15_exp <- exp(log_15)
log_15_exp
```

For example, we might want to estimate the number of gestures infants produce in a laboratory session. See [Cameron 2020](https://uoelel.github.io/qml-data/data/cameron2020/gestures.html) for a description of the study and data variables.

```{r}
#| label: gestures
gestures <- read_csv("data/cameron2020/gestures.csv")
gestures
```

Let's estimate the number of gestures (`count`) depending on the cultural background (`background`). I recommend creating plots of the data before moving on.

Here's the model mathematical formula.

$$
\begin{align}
\text{N}_i & \sim Poisson(\lambda_i) \\
\ln(\lambda_i) & = \alpha_{\text{B}_i}
\end{align}
$$

- $\text{N}_i$ is the number of gestures.
- $Poisson(\lambda_i)$ tells us that the number of gestures follows a Poisson distribution.
- $\ln()$ is simply the natural logarithm.
- $\ln(\lambda_i)$ is equal to $\alpha$, which differs depending to the type of the gesture ($\alpha_{\text{B}_i}$), where $\text{G}_i$ is either "Cantonese", "Bengali" or "English".

You can read it the first line as:

> The number of gestures follows a Poisson distribution with rate $\lambda_i$.

## Counts log-odds

Counts are a discrete numeric variable, bounded to 0 and positive numbers only. As we have learnt with Bernoulli models, regression models don't work with bounded variables out of the box. We need to transform counts into a scale that is continuous and unbounded.

This is where the **logarithmic function** from the mathematical formula above comes in: the logarithmic function (from "*log*istic un*it*") is a mathematical function that logs numbers.

The plot below shows the correspondence of numbers (on the *y*-axis) and logged values (on the *x*-axis), as marked by the black dots. It is helpful to memorise that the log of 1 is 0.

```{r}
#| label: p-log-odds
#| warning: false
#| echo: false

count_log <- tibble(
  count = seq(1, 25),
  log = log(count)
) %>%
  ggplot(aes(count, log)) +
  geom_point() +
  scale_x_continuous(breaks = seq(1, 25), minor_breaks = NULL) +
  labs(
    title = "Correspondence between counts and logged values",
    x = "Counts",
    y = "Logged counts"
  )
count_log
```

When you fit a regression model with a Poisson distribution, the estimates are log-odds, on the log scale. When you exponentiate the estimates, you go back to the original scale, i.e. counts.

## Fitting a Poisson model

### The data

To illustrate how to fit a Bernoulli model, we will use data from [Brentari 2024](https://uoelel.github.io/qml-data/data/brentari2024/verb_org.html) on the emergent Nicaraguan Sign Language (*Lengua de Señas Nicaragüense*, NSL).

```{r}
#| label: verb-org

verb_org <- read_csv("data/brentari2024/verb_org.csv")
```

`verb_org` contains information on predicates as signed by three groups (`Group`): home-signers (`homesign`), first generation NSL signers (`NSL1`) and second generation NSL signers (`NSL2`). Specifically, the data coded in `Num_Predicates` whether the predicates uttered by the signer were single-verb predicates (SVP, `single`) or a multi-verb predicates (MVP, `multiple`). The hypothesis of the study is that use of multi-verb predicates would increase with each generation, i.e. that NSL1 signers would use more MVPs than home-signers and that NSL2 signers would use more MVPs than home-signers and NSL1 signers. (For the linguistic reasons behind this hypothesis, check the paper linked above).

Let's plot the data to learn a bit more about it.

```{r}
#| label: verb-org-plot

verb_org |> 
  ggplot(aes(Group, fill = Num_Predicates)) +
  geom_bar(position = "fill")
```

What do you notice about the type of predicates in the three groups?

To assess the study hypothesis, we can fit a Bernoulli model with `Num_Predicates` as the outcome variable and `Group` as the predictor.

Before we move on onto fitting the model, it is useful to transform `Num_Predicates` into a factor and specify the order of the levels so that `single` is the first level and `multiple` is the second level.

This is useful because Bernoulli models estimate the probability (the parameter $p$ in $Bernoulli(p)$ of getting the *second* level in the outcome variable.

You can also think of this in terms of `0`s and `1`s: the first level is assigned to `0` and the second level is assigned to `1`. Then a Bernoulli distribution with probability $p$ tells you the probability of getting a `1`. It doesn't matter how you prefer to think about Bernoulli distributions, as long as you remember that the probability being estimated is the probability of the *second* level.

Now let's mutate `verb_org`.

```{r}
#| label: num-preds-mutate

verb_org <- verb_org |> 
  mutate(
    Num_Predicates = factor(Num_Predicates, levels = c("single", "multiple"))
  )
```

If you reproduce the plot above you will see now that the order of `Num_Predicates` in the legend is "single" then "multiple" and that the order of the proportions in the bar chart have flipped.

Now we can move on onto modelling.

### The model

$$
\begin{align}
\text{Num\_Preds}_{MVP} & \sim Bernoulli(p_i) \\
logit(p_i) & = \alpha_{\text{Group}[i]} \\
\end{align}
$$

-   The probability of using an MVP follows a Bernoulli distribution with probability $p$.

-   The log-odds of $p$ are equal to $\alpha$ for each Group.

In other words, the model estimates $p$ for each group. Here is the code. Remember that to use the indexing approach for categorical predictors (`Group`) we need to suppress the intercept with the `0 +` syntax.

```{r}
#| label: mvp-bm

mvp_bm <- brm(
  Num_Predicates ~ 0 + Group,
  family = bernoulli,
  data = verb_org,
  cores = 4,
  seed = 1329,
  file = "data/cache/regression-bernoulli_mvp_bm"
)
```

Let's inspect the model summary (we will get 80% CrIs).

```{r}
#| label: mvp-bm-summ

summary(mvp_bm, prob = 0.8)
```

Based on the model, there is an 80% probability that the log-odds of a MVP are between -0.76 and -0.38 in home-signers, between -1.68 and -1.24 in NSL1 signers and between -0.21 and 0.16 in NSL2 signers.

It's easier to understand the results if we convert the log-odds to probabilities. The quickest way to do this is to get the `Regression Coefficients` table from the summary with `fixef()` and mutate the `Q` columns with `plogis()`.

```{r}
#| label: mvp-bm-p

fixef(mvp_bm, prob = c(0.1, 0.9)) |>
  # we need to convert the output of fixef() to a tibble to use mutate()
  as_tibble() |>
  # we plogis() the Q columns and round to the second digit
  mutate(
    Q10 = round(plogis(Q10), 2),
    Q90 = round(plogis(Q90), 2)
  )
```

Based on the model, there is an 80% probability that the probability of using an MVP is between 32-41% in home-signers, between 16-22% in NSL1 signers and between 45-54% in NSL2 signers.

We can now see more clearly that the hypothesis of the study is not fully borne out by the data: while NSL2 signers are more likely to use an MVP than home-signers and NSL1 signers, it is not the case that NSL1 signers are more likely to use MVPs than home-signers.

To conclude this introduction to Bernoulli models (aka binomial/logistic regressions) we can get the predicted probabilities of use of MVPs in the three groups with `conditional_effects()`.

```{r}
#| label: mvp-bm-cond

conditional_effects(mvp_bm)
```
